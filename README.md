## Cloud Practitioner Essentials (Belajar Dasar AWS Cloud)

### Glosarium
<p align="justify">
<b> Artificial Intelligence</b></br>
Artificial Intelligence adalah kemampuan komputer untuk bertindak seperti manusia.</br></br>
<b> Blockchain</b></br>
Blockchain adalah catatan transaksi digital. Nama “blockchain” berasal dari strukturnya, di mana catatan individu (disebut sebagai block) dihubungkan bersama dalam daftar tunggal (disebut sebagai chain). Blockchain digunakan untuk mencatat transaksi yang dilakukan dengan cryptocurrency, seperti Bitcoin, dll.</br></br>
<b>  Cloud</b></br>
Dalam dunia IT, cloud mengacu pada server yang diakses melalui Internet, serta perangkat lunak dan database yang berjalan di server tersebut</br></br>
<b>  Compliance</b></br>
Dalam tata kelola perusahaan, compliance berarti mengikuti suatu spesifikasi, standar, atau hukum yang telah diatur dengan jelas yang biasanya diterbitkan oleh lembaga atau organisasi yang berwenang dalam suatu bidang tertentu.</br></br>
<b>  Database</b></br>
Struktur data yang menyimpan informasi yang terorganisir.</br></br>
<b>  Deploy</b></br>
Dalam konteks IT, deploy merujuk pada semua proses yang terlibat dalam mendapatkan software atau hardware rilis dan berjalan dengan baik, termasuk instalasi, konfigurasi, pengoperasian, pengujian, dan membuat perubahan yang diperlukan.</br></br>
<b>  Entitas</b></br>
Satu objek unik di dunia nyata. Ia mengacu pada individu, organisasi, produk, atau komponen sistem.</br></br>
<b>  Exabyte</b></br>
Exabyte adalah 1018 atau 1.000.000.000.000.000.000 byte. 1 exabyte sama dengan 1.000 petabyte.</br></br>
<b>  Hard Drive</b></br>
Hard drive adalah tempat menyimpan semua data Anda. Data tersebut disimpan di secara magnetis, sehingga tetap berada di drive bahkan setelah daya dimatikan. Istilah "hard drive" sebenarnya adalah singkatan dari "hard disk drive", keduanya merujuk pada arti yang sama.</br></br>
<b>  Hypervisor</b></br>
Program perangkat lunak yang mengelola satu atau lebih mesin virtual. Hypervisor digunakan untuk membuat, memulai, menghentikan, dan mengatur ulang VM.</br></br>
<b>  Instance</b></br>
Instance adalah server virtual di AWS Cloud.</br></br>
<b>  Latensi</b></br>
Waktu yang diperlukan untuk mengirim dan menerima data.</br></br>
<b>  Machine Learning</b></br>
Sebuah jenis dari Artificial Intelligence yang dapat "belajar" atau beradaptasi dari waktu ke waktu.</br></br>
<b>  On-premise</b></br>
Penyimpanan dan pemeliharaan data di server lokal atau pribadi.</br></br>
<b>  Permission</b></br>
Permission diartikan sebagai memberikan persetujuan atau otorisasi atau mengizinkan seseorang untuk melakukan sesuatu. Pada konteks AWS, permission memungkinkan Anda untuk menentukan akses ke sumber daya AWS.</br></br>
<b>  Petabyte</b></br>
Petabyte adalah 1015 atau 1.000.000.000.000.000 byte. 1 petabyte sama dengan 1.000 terabyte.</br></br>
<b>  Sumber Daya</b></br>
Di AWS, sumber daya (resource) berarti entitas yang dapat Anda pakai, contohnya Amazon EC2 instance atau Amazon S3 bucket.</br></br>
<b>  Terabyte</b></br>
Terabyte adalah 1012 atau 1.000.000.000.000 byte. 1 terabyte sama dengan 1.000 gigabyte.</br></br>
<b>  Throughput</b></br>
Jumlah data yang dapat dikirim dalam waktu tertentu.</br></br>
<b>  Web Hosting</b></br>
Web Hosting menyimpan semua halaman website Anda dan membuatnya tersedia untuk komputer yang terhubung ke Internet.</br></br> </p>

### Pengantar ke Amazon Web Services

<p align="justify"> Selamat datang di Kelas Cloud Practitioner Essentials! Kelas ini adalah kelas dasar yang hadir untuk mengenalkan Anda pada layanan komputasi cloud dengan Amazon Web Services atau biasa disingkat AWS. </br> </br>Amazon Web Services atau AWS adalah salah satu layanan penyedia komputasi cloud yang telah hadir di seluruh dunia. AWS merupakan platform cloud yang paling komprehensif dan digunakan secara luas. Faktanya, jumlah layanan di AWS mencapai lebih dari ratusan layanan unggulan dengan jutaan pelanggan. </br> </br>Dengan cloud seperti AWS ini, pengguna dari berbagai kalangan perusahaan IT, pada umumnya, menjadi lebih tangkas dalam menjalankan aktivitas operasional sehari-hari dan lebih cepat dalam berinovasi. </br> </br>Di kelas ini kita akan mempelajari setiap materi secara terstruktur. Mari awali langkah perjalanan kita dengan beberapa pertanyaan terkait Kelas Cloud Practitioner Essentials.</p>
  
### Siapa yang dapat mengambil kelas ini?
<p align="justify"> Kelas Cloud Practitioner Essentials ini ditujukan bagi Anda yang mencari pemahaman secara keseluruhan tentang AWS Cloud, terlepas dari latar belakang pekerjaan tertentu. Kelas ini pun ditujukan bagi Anda yang bekerja di bidang berikut:
  </p>

<ol type="1"><li>Sales</li>
<li>Hukum</li>
<li>Pemasaran</li>
<li>Analis bisnis</li>
<li>Manajer proyek</li>
<li>Pelajar AWS Academy</li>
<li>Profesi lain terkait IT</li></ol>

### Apa saja prasyarat untuk mengambil kelas ini?
<p align="justify"> Untuk mulai mempelajari kelas ini, setidaknya Anda harus memahami beberapa pengetahuan dasar seperti berikut:</p>
<ul align="justify"><li>
Teknis IT secara umum. Minimal Anda mengenal istilah komputer, jaringan, perangkat keras, perangkat lunak, web, dan internet.</li>
<li>Bisnis IT secara umum. Anda mengetahui perusahaan-perusahaan yang bergerak di dunia IT seperti Amazon.</li></ul>
  
  ### Apa saja yang akan kita pelajari?
  <p align="justify"> Jangan khawatir jika Anda tidak memiliki pengetahuan sama sekali tentang komputasi cloud atau bahkan Amazon Web Services, karena materi yang dibahas pada kelas ini tergolong ringan dan disajikan dengan bahasa yang mudah dipahami. Sebelum mengikuti kelas ini, Anda perlu tahu terlebih dahulu modul apa saja yang ada di dalamnya</br></br>
Kelas ini terdiri dari 11 modul yang akan membahas tentang pengenalan konsep AWS Cloud, layanan-layanannya, keamanan, arsitektur, harga dan dukungan, kemudian ditutup dengan penilaian akhir berupa ujian sehingga menambah pengetahuan dan wawasan Anda mengenai AWS Cloud menjadi lebih baik.</br> </br>
Ketahuilah! Karena kelas Cloud Practitioner Essentials (Belajar Dasar AWS Cloud) ini didesain untuk berbagai macam latar belakang profesi dan dibuat semudah mungkin, sehingga pembahasan materi pada setiap modul hanya akan berisi teori saja.
</br> </br>Berikut adalah materi-materi yang akan Anda perdalam / pelajari secara komprehensif:
  </p>
<ul align="justify"><li><b> Modul 1: Pengantar ke Amazon Web Services</b></br>
Menjelaskan tentang materi pengenalan, seperti apa saja yang harus Anda siapkan sebelum mengikuti kelas; manfaat dari AWS; perbedaan antara penyajian on-demand (sesuai permintaan) dan model penerapan cloud; serta model biaya dengan skema pay-as-you-go.</li>
<li><b>Modul 2: Komputasi di Cloud </b></br>
Membahas materi komputasi di cloud, yakni manfaat dari Amazon Elastic Compute Cloud (Amazon EC2) di level dasar; perbedaan tipe dari Amazon EC2 instance; perbedaan antara variasi pilihan penagihan untuk Amazon EC2; manfaat Amazon EC2 Auto Scaling; manfaat Elastic Load Balancing, contoh penggunaan Elastic Load Balancing; perbedaan antara Amazon Simple Notification Service (Amazon SNS) dan Amazon Simple Queue Services (Amazon SQS); serta layanan komputasi lain di AWS.</li>
<li><b>Modul 3: Infrastruktur Global dan Keandalan</b></br>
Menelaah materi terkait infrastruktur global AWS; konsep dasar Availability Zone; manfaat Amazon CloudFront dan Edge locations; serta membandingkan perbedaan metode untuk penyajian layanan AWS.</li>
<li><b>Modul 4: Jaringan</b></br>
Mengupas tuntas materi jaringan, seperti konsep dasarnya; perbedaan antara sumber daya jaringan publik dan privat; virtual private gateway dan virtual private network (VPN) untuk menghubungkan AWS Cloud dengan jaringan lain; AWS Direct Connect; manfaat penerapan arsitektur hybrid; lapisan keamanan yang digunakan dalam strategi IT; dan layanan yang digunakan untuk berinteraksi dengan jaringan global AWS.</li>
<li><b>Modul 5: Penyimpanan dan Database</b></br>
Mengulas konsep dasar penyimpanan dan databases (basis data); manfaat Amazon Elastic Block Store (Amazon EBS); Amazon Simple Storage Service (Amazon S3); Amazon Elastic File System (Amazon EFS); variasi solusi penyimpanan; Amazon DynamoDB; dan terakhir ragam layanan database.</li>
<li><b>Modul 6: Keamanan</b></br>
Mendeskripsikan materi keamanan, yakni manfaat shared responsibility model (model tanggung jawab bersama); multi-factor authentication (autentikasi multifaktor) atau MFA; tingkat keamanan AWS Identity and Access Management (IAM); dasar-dasar kebijakan keamanan; AWS Organizations; compliance (kepatuhan) dengan AWS; dan layanan keamanan utama AWS yang mudah.</li>
<li><b>Modul 7: Pemantauan dan Analitik</b></br>
Menelaah pendekatan untuk memantau environment (lingkungan) AWS Anda, manfaat Amazon CloudWatch, AWS CloudTrail, dan AWS Trusted Advisor.</li>
<li><b>Modul 8: Harga dan Dukungan</b></br>
Menguraikan materi terkait model harga dan dukungan, seperti AWS Free Tier (Tingkat Gratis); AWS Organizations dan consolidated billing (tagihan terkonsolidasi); AWS Budgets; AWS Cost Explorer; AWS Pricing Calculator; membedakan setiap AWS Support Plans; dan terakhir AWS Marketplace.</li>
<li><b>Modul 9: Migrasi dan Inovasi</b></br>
Mengkaji materi terkait migrasi dan inovasi di AWS Cloud, yaitu AWS Cloud Adoption Framework (AWS CAF); enam faktor utama dari strategi migrasi cloud; manfaat beragam solusi migrasi data: AWS Snowcone, AWS Snowball, dan AWS Snowmobile; dan terakhir, meringkas cakupan luas dari solusi inovatif yang ditawarkan AWS.</li>
<li><b>Modul 10: Perjalanan Cloud</b></br>
Menjelaskan lima pilar dari AWS Well-Architected Framework dan enam manfaat dari komputasi cloud.</li>
<li><b>Modul 11: Dasar-Dasar AWS Certified Cloud Practitioner</b></br>
Mengulik sumber daya untuk persiapan ujian AWS Certified Cloud Practitioner sekaligus manfaat menjadi seseorang yang bersertifikat AWS.</li>
<li><b>Penilaian Akhir Kelas</b></br>
Penilaian akhir ini berisi soal-soal yang mendekati ujian AWS Certified Cloud Practitioner.  </li></ul>

<p align="justify"> AWS menawarkan berbagai macam layanan untuk setiap kegunaan. Dimulai dengan elemen dasar, seperti komputasi, penyimpanan, dan keamanan jaringan, hingga solusi kompleks seperti blockchain, machine learning, atau artificial intelligence (kecerdasan buatan), serta platform pengembangan robot.</br> </br>Namun semua hal tersebut nampaknya terlalu kompleks dan perlu lebih banyak waktu untuk kita bahas di kelas dasar seperti ini. Jadi, mari kita sederhanakan pembahasan kita dengan memulai dari model komputasi cloud dasar.</br> </p>Tahukah Anda? Hampir semua model komputasi modern adalah berbentuk client-server
<p align="center">
  <img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210327171832f42e6e357ebace3e1a19267c10a6bba7.png" width="350" title="hover text"></p>

  <p align="justify"> Dalam dunia komputasi, client dapat berupa web browser atau aplikasi yang dapat membuat permintaan ke server. Sebuah server dapat berupa layanan seperti Amazon Elastic Compute Cloud (Amazon EC2).</br></br>Contoh interaksinya adalah client membuat permintaan untuk mengakses sebuah artikel berita, skor dalam game online, atau video lucu lalu server mengevaluasi detail permintaan tersebut dan memenuhinya dengan mengembalikan informasi ke client.</br></br>
Oke, mungkin pembahasan di atas terlalu teknis ya. Bagaimana kalau kita membuat suatu perumpamaan yang dapat digunakan secara berkelanjutan di setiap modulnya? Tapi perumpamaan seperti apa ya yang dapat mencakup setiap pembahasan di kelas ini?</br></br>
Bagaimana dengan skenario kedai kopi? Sepertinya menarik. Kedai kopi ini akan memberi kita beberapa metafora dunia nyata untuk membantu Anda memahami mengapa AWS dapat mengubah cara pengoperasian IT di seluruh dunia.</br></br>
Kita mulai dari sebuah pertanyaan dasar. Apa saja elemen yang ada di sebuah kedai kopi? Kasir dan pelanggan, tentu.
  </p>
  <p align="center">
  <img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210327171900e59eabc83109d5738c729956eadd2cfb.png" width="350" title="hover text"></p>
  <p align="justify"> Dalam model client-server. Kasir berperan sebagai server sedangkan pelanggan adalah client. Di kedai kopi pelanggan membuat suatu permintaan berupa segelas kopi. Namun di dunia komputasi, permintaan dapat berbentuk apa pun: analisis pola hujan di negara Afrika Selatan, rontgen terbaru dari lutut Anda, atau mungkin video anak kucing yang menggemaskan.</br>
Apa pun bisnisnya, pada dasarnya client membuat suatu permintaan--tentu dengan telah memiliki izin akses--kemudian server menanggapi permintaan tersebut.Kembali ke kedai kopi. Kasir adalah server-nya. Di AWS, kasir tersebut diberi nama Amazon Elastic Compute Cloud (EC2), sebuah server virtual dan kita akan memanggilnya instance.Mari kita lihat proses transaksi yang terjadi antara kasir dan pelanggan ini dari sudut pandang arsitektural.
  </p>
  
  <ul align="justify"><li>Pelanggan (client) membuat permintaan ke kasir (server).</li>
<li>Kasir memvalidasi bahwa permintaan tersebut sah, dalam hal ini apakah pelanggan telah membayar atau belum.</li>
<li>Jika ya, maka kasir akan ke belakang untuk membuat kopi sesuai permintaan.</li>
<li>Setelah selesai, kasir tersebut akan kembali kepada pelanggan dengan membawa kopinya, dalam hal ini adalah kapucino dengan ekstra karamel. Yummy!</li></ul>
  <p align="justify"> Di dunia nyata, aplikasi bisa lebih rumit dari sekadar satu transaksi dengan satu server, bahkan bisa menjadi sangat kompleks ketika diterapkan ke dalam solusi bisnis yang mapan. Nah, untuk menghindari kompleksitas ini, mari kita mulai dengan yang simpel, seperti konsep utama di AWS, yakni pay for what you use (bayar untuk apa yang Anda gunakan). </br>Prinsip ini sangat tepat dan masuk akal dengan skenario kedai kopi kita. Pegawai hanya dibayar saat mereka bekerja di toko. Jika mereka tidak bekerja, maka tidak ada gaji. Pemilik kedai dapat memutuskan berapa banyak pegawai yang dia butuhkan lalu memberikan mereka upah sesuai jam kerja.</br></br>
Sebagai contoh, kedai kopi tersebut akan merilis minuman baru, Robusta. Delicioso! Untuk mengantisipasi peluncuran ini, Anda bisa mempekerjakan selusin pegawai sepanjang hari guna berjaga-jaga jika pelanggan membludak berdatangan secara tak terduga di hari spesial tersebut. Hanya saja, pelanggan tidak selalu akan membludak setiap saat, bukan?</br>
Tapi tahukah Anda? Inilah yang sebenarnya terjadi di data center on-premise (lokal). Anda tidak bisa hanya sekadar menjentikkan jari lalu voila! Kapasitas Anda berlipat ganda dengan sendirinya. Nope. Banyak proses administratif yang perlu Anda lakukan dan berujung pada mahalnya biaya yang perlu Anda keluarkan.</br>
Dengan Amazon Web Service, Anda tidak perlu membayar uang muka untuk apa pun dan tidak perlu khawatir tentang kendala kapasitas.</br>
Oke. Sekarang kita menemukan istilah baru, data center on-premise. Apa itu? Mari kita kupas.</br>
Pertama, data center. Berdasarkan website Cisco--salah satu perusahaan telekomunikasi global--data center adalah fasilitas yang digunakan perusahaan untuk menempatkan aplikasi dan data penting mereka. Komponen utama dari data center adalah router, switch, firewall, sistem penyimpanan, dan juga server. </br>
Sementara on-premise mengacu pada penyimpanan dan pemeliharaan data di server lokal atau pribadi.</br>
Lanjut ke prinsip berikutnya, yaitu pay for what you need (bayar untuk apa yang Anda butuhkan). Misal ketika Anda membutuhkan sebuah instance atau mungkin barista, cukup dengan klik sebuah tombol ajaib segera mereka pun seketika tersedia untuk Anda. Dan ketika tak membutuhkannya, klik tombol lagi kemudian mereka akan pergi sesaat kemudian sehingga Anda tak perlu membayarnya lagi.</br>
Prinsip ini menjadi nilai utama di AWS. Itulah alasan sebenarnya kelas ini dihadirkan, yakni untuk membantu Anda memahami bagaimana AWS dibangun untuk membantu Anda menjalankan bisnis dengan lebih baik. Tetaplah pahami dan ikuti kelas ini dengan saksama karena kita akan segera menyelami konsep-konsep tersebut lebih dalam serta membantu Anda melangkah menuju Cloud Practitioner. Semangat!
  </p>
  
  <p align="justify"> Model Penerapan untuk Komputasi Cloud
Saat memilih strategi untuk menerapkan cloud, Anda harus mempertimbangkan beberapa faktor, seperti komponen aplikasi cloud yang diperlukan, layanan manajemen sumber daya yang dibutuhkan, dan setiap persyaratan infrastruktur IT.</br>
Tiga model penerapan komputasi cloud adalah cloud-based, on-premises (lokal), dan hybrid. Mari kita uraikan masing-masing model tersebut: </p>

<ul align="justify"><li><b>Cloud-based Deployment</b></br>
Dalam model penerapan cloud-based, Anda dapat merancang, membangun, dan menjalankan aplikasi baru di cloud. Anda pun dapat memigrasikan aplikasi yang telah ada ke cloud.
Anda dapat membangun aplikasi tersebut pada low-level infrastructure (infrastruktur tingkat rendah) yang mana memerlukan staf IT Anda untuk mengelolanya. Atau dengan alternatif lain, yaitu menggunakan higher-level services (layanan dengan tingkat lebih tinggi) sehingga mengurangi kebutuhan pengelolaan, arsitektur, dan scaling (penyesuaian kapasitas) pada infrastruktur Anda.
Misalnya, Anda dapat membuat aplikasi yang terdiri dari server virtual, database, dan komponen jaringan yang sepenuhnya berbasis di cloud.</li>

<li><b>On-premises Deployment</b></br>
On-premises juga dikenal sebagai private cloud (cloud privat). Dalam model ini, sumber daya di-deploy (diterapkan) menggunakan layanan manajemen aplikasi dan teknologi virtualisasi pada data center pribadi sehingga penggunaan dan pemanfaatannya dapat meningkat.</li>

<li><b>Hybrid Deployment</b></br>
Dalam penerapan hybrid, sumber daya berbasis cloud terhubung ke data center on-premises (lokal). Anda bisa gunakan pendekatan ini untuk beberapa situasi, seperti aplikasi lama yang memang lebih baik dikelola di on-premises atau mungkin karena peraturan pemerintah yang mengharuskan Anda menyimpan data tertentu di data center lokal.</li></ul>

<p align="justify"> Manfaat dari Komputasi Cloud
Ada beberapa hal yang perlu Anda pertimbangkan agar semakin yakin untuk memilih komputasi cloud sebagai solusi yang dapat menangani kebutuhan Anda dibandingkan dengan data center on-premise. Mari kita uraikan:</p>

<ul align="justify"><li><b>Ubah pengeluaran di muka menjadi pengeluaran variabel</b></br>
Pengeluaran di muka (upfront expense) mengacu pada data center, server fisik, dan sumber daya lain yang perlu Anda investasikan sebelum Anda menggunakannya. Sedangkan pengeluaran variabel (variable expense) berarti Anda hanya membayar untuk sumber daya komputasi yang Anda konsumsi. Dengan mengambil pendekatan komputasi cloud yang menawarkan keuntungan biaya variabel, perusahaan dapat mengimplementasikan solusi inovatif sekaligus menghemat biaya.</li>

<li><b>Hentikan biaya pengelolaan dan pemeliharaan data center</b></br>
Komputasi di data center sering kali mengharuskan Anda untuk mengeluarkan lebih banyak biaya dan waktu untuk mengelola infrastruktur dan server. Nah, dengan komputasi cloud, Anda tak perlu lagi khawatir akan tugas-tugas ini. Dengan begitu, Anda dapat lebih fokus pada aplikasi dan pelanggan Anda.</li>

<li><b>Berhenti menebak kapasitas</b></br>
Dengan komputasi cloud, Anda tak perlu memprediksi berapa banyak kapasitas infrastruktur yang Anda perlukan sebelum men-deploy aplikasi. Misalnya, Anda dapat meluncurkan Amazon EC2 instance dan cukup membayar untuk waktu komputasi yang digunakan. Daripada harus membayar sumber daya yang tak terpakai atau berurusan dengan kapasitas yang terbatas, dengan komputasi cloud, Anda dapat menggunakan kapasitas sesuai keinginan. Bahkan Anda juga dapat melakukan proses scale in (mengurangi) atau scale out (memperbanyak) kapasitas sesuai permintaan.</li>

<li><b>Manfaatkan skala ekonomi yang masif</b></br>
Dengan menggunakan komputasi cloud, Anda dapat mewujudkan biaya variabel yang lebih rendah daripada yang dapat Anda peroleh dari data center on-premise. Penggunaan dari ratusan ribu pelangganlah yang memungkinkan AWS dapat mencapai skala ekonomi (economies of scale) yang lebih tinggi. Kemudian skala ekonomi ini diterjemahkan ke dalam harga pay-as-you-go yang lebih murah.</li>

<li><b>Tingkatkan kecepatan dan ketangkasan</b></br>
Fleksibilitas dari penggunaan komputasi cloud memudahkan Anda untuk mengembangkan dan men-deploy aplikasi. Dengan komputasi cloud, Anda memiliki lebih banyak waktu untuk bereksperimen dan berinovasi. Tentu ini tak bisa Anda lakukan jika menggunakan data center on-premise. Misal untuk mendapatkan sumber daya baru, mungkin Anda memerlukan waktu berminggu-minggu. Sedangkan dengan AWS, sumber daya baru akan langsung siap diakses dalam hitungan menit.</li>

<li><b>Mendunia dalam hitungan menit</b></br>
AWS Cloud memungkinkan Anda dapat meluncurkan aplikasi ke pelanggan di seluruh dunia dengan cepat sekaligus memberikan latensi yang rendah. Ini berarti meskipun Anda berada di belahan dunia yang berbeda dengan pelanggan, mereka tetap dapat mengakses aplikasi dengan waktu tunda (delay) yang minimal.</li></ul>
  
  ### Pengenalan ke Amazon Elastic Compute Cloud (Amazon EC2)
<p align="justify"> 
Bisnis perawatan kesehatan, manufaktur, asuransi, ataupun pengiriman konten video. Itu semua menggunakan model client-server untuk menyajikan produk, sumber daya, atau data ke pelanggan. Maka dari itu, Anda membutuhkan server yang dapat memberikan kapasitas komputasi untuk menjalankan aplikasi dan menyediakan daya komputasi sesuai kebutuhan bisnis Anda. Di AWS server tersebut berbentuk virtual. Dan layanan yang dapat Anda gunakan untuk mendapatkan akses ke server virtual tersebut disebut dengan <b>Amazon EC2. </b>
Dengan menggunakan layanan EC2, Anda memiliki kapasitas komputasi yang fleksibel, hemat biaya, dan cepat dibandingkan dengan menjalankan server sendiri di data center on-premise. Bayangkan, untuk mengaktifkan dan menjalankan sumber daya di on-premise, Anda memerlukan banyak waktu dan biaya. Coba kita uraikan bagaimana prosesnya.</p>
<ul align="justify"><li>
Pertama, Anda harus melakukan banyak riset untuk mengetahui jenis server apa yang ingin dibeli dan berapa banyak yang diperlukan. </li>
<li>Setelah itu, Anda membelinya dengan biaya di muka yang cukup menguras kantong. Lalu masuklah ke proses yang memakan waktu, yaitu Anda mesti menunggu beberapa minggu atau bahkan berbulan-bulan sampai server tersebut tersedia untuk Anda.</li>
Anggaplah server tersebut sudah tiba di bangunan data center yang Anda miliki atau sewa.</li>
<li>Langkah selanjutnya, Anda perlu memasang, menyusun, dan menghubungkan semuanya.</li>
<li>Kemudian, pastikan server-server tersebut aman dan menyala dengan baik, barulah mereka siap untuk digunakan.</li></ul>
<p align="justify"> 
Hanya dengan cara itulah Anda bisa mulai menjalankan aplikasi di server ini. Satu kata: “huft!” Sangat melelahkan. Eh tapi, tunggu! Masih ada bagian terburuknya. Setelah membeli server-server ini, Anda terjebak dengan mereka, entah Anda menggunakannya secara maksimal atau tidak. Nah, tentu ini akan jauh berbeda jika Anda menggunakan AWS.</br>
Amazon EC2 memberikan kapasitas komputasi yang aman dan dapat Anda ubah-ubah ukurannya di cloud. Masih ingat persoalan sulitnya mengaktifkan dan menjalankan sumber daya di on-premise pada materi sebelumnya?</br>
Nah, dengan Amazon EC2, proses tersebut akan jauh lebih mudah. Jangan khawatir! AWS sudah menangani bagian-bagian yang sulit untuk Anda. AWS telah membangun dan mengamankan data center, membeli, menyusun, dan memasang server sehingga siap untuk Anda gunakan.</br>
AWS terus mengoperasikan kapasitas komputasi dalam jumlah besar sehingga Anda dapat menggunakannya kapan pun dan berapa pun sesuai dengan porsi kapasitas yang Anda butuhkan. Anda hanya perlu membuat permintaan untuk EC2 instance sesuai keinginan dan saat itu juga mereka pun tersaji dalam hitungan menit. Di AWS, server virtual disebut sebagai instance.</br>
Nah, jika telah selesai menggunakannya, Anda dapat menghentikan atau mengakhiri instance tersebut dengan mudah. Anda tidak perlu lagi khawatir akan terjebak dengan server yang tidak digunakan. Anda hanya harus membayar sesuai dengan apa yang Anda gunakan saja (pay for what you use), bukannya saat instance berhenti atau berakhir.</br>
Amazon EC2 berjalan di atas host (mesin fisik) yang dikelola oleh AWS menggunakan teknologi virtualisasi. Saat menjalankan instance, Anda tidak menggunakan keseluruhan mesin host untuk sendiri melainkan Anda akan berbagi mesin host dengan beberapa instance lainnya. Ini dikenal dengan nama virtual machines alias mesin virtual.</br>
Hypervisor-lah yang bertanggung jawab untuk membagi sumber daya fisik yang mendasarinya di antara mesin virtual tersebut. Ini sepenuhnya dikelola oleh AWS. Ide berbagi perangkat keras yang mendasarinya ini disebut multitenancy. Hypervisor juga bertanggung jawab untuk mengisolasi mesin virtual satu sama lain saat mereka berbagi sumber daya dari host. Ini berarti EC2 instance tetap aman meskipun mereka berbagi sumber daya. Satu instance tidak akan mengetahui keberadaan instance lainnya walau mereka ada di host yang sama. Mereka tetap aman dan terpisah satu sama lain.</br>
Amazon EC2 memberikan Anda banyak fleksibilitas dan kontrol. Tak hanya dapat menjalankan server baru atau menghentikannya sesuka hati, Anda juga memiliki kuasa atas konfigurasinya.</br>
Misal pada saat Anda membuat EC2 instance. Anda dapat memilih OS (operating system/sistem operasi) yang Anda inginkan, baik itu Windows atau Linux. Anda juga dapat membuat ribuan instance EC2 sekaligus dengan perpaduan sistem operasi dan konfigurasi sehingga dapat mendukung berbagai aplikasi bisnis Anda.</br>
Selain OS, Anda juga dapat melakukan instalasi perangkat lunak apa yang ingin dijalankan pada instance. Baik itu aplikasi bisnis internal, web sederhana, web yang kompleks, database (basis data), hingga perangkat lunak pihak ketiga seperti paket perangkat lunak perusahaan. Anda memiliki kendali penuh atas apa yang ada di instance tersebut.</br>
Instance EC2 juga dapat diubah-ubah ukurannya. Anda dapat mulai dengan menggunakan small instance (instance dengan tipe small).
Ketika aplikasi yang Anda jalankan mulai membutuhkan kapasitas yang lebih besar, Anda dapat menambahkan lebih banyak memori dan CPU. Itulah yang dinamakan vertical scaling atau mengatur skala instance secara vertikal. Intinya, Anda dapat membuat instance lebih besar atau lebih kecil kapan pun Anda mau.</br>
Bahkan tak hanya itu. Anda juga dapat mengontrol aspek jaringan dari EC2, seperti jenis permintaan apa yang diizinkan atau bagaimana instance dapat diakses (publik atau privat). Di modul berikutnya kita akan membahas lebih lanjut berkenaan jaringan.</br>
Sekali lagi, Amazon EC2 berjalan dengan bantuan teknologi virtualisasi. Mungkin Anda sudah tak asing ya dengan istilah mesin virtual. Yup! Karena ini bukanlah sesuatu yang baru.
</br>
Namun AWS membuat proses penyediaan server menjadi lebih mudah dan lebih hemat melalui model Compute as a Service (CaaS) seperti Amazon EC2 ini. Dengan semua keuntungan tersebut, programmer dan bisnis dapat berinovasi lebih cepat.</p>

### Cara Kerja Amazon EC2
<p align="justify">
Mungkin kening Anda sempat sedikit mengerut, “Bagaimana cara kerja Amazon EC2?” Tak seperti server di data center yang memerlukan proses panjang, Amazon EC2 dapat digunakan dengan mudah dengan beberapa langkah saja.</p>
<ul align="justify"><li><b>Luncurkan</b></br>
Mulailah dengan memilih sebuah template dengan konfigurasi dasar untuk instance Anda. Konfigurasi dasar ini termasuk sistem operasi, server aplikasi, atau aplikasi lainnya. Anda juga dapat memilih tipe instance, yaitu konfigurasi perangkat keras tertentu dari instance Anda.</li>
Selagi menyiapkan peluncuran instance, tentukanlah pengaturan keamanan untuk mengontrol lalu lintas jaringan yang dapat mengalir masuk dan keluar instance Anda. Nanti kita akan menjelajahi fitur keamanan Amazon EC2 secara lebih detail di materi selanjutnya.</li>
<li><b>Hubungkan</b></br>
Anda dapat terhubung ke instance dengan beberapa cara. Program dan aplikasi Anda memiliki beberapa metode berbeda untuk terhubung dan bertukar data langsung ke instance. Anda dapat terhubung juga ke instance dengan mengaksesnya dari desktop.</li>
  <li><b>Gunakan</b></br>
Setelah terhubung ke instance, Anda dapat mulai menggunakannya. Ada banyak hal yang bisa dilakukan dengan Amazon EC2 instance, seperti menginstal perangkat lunak, menambah penyimpanan, menyalin dan mengatur file, dll.</li></ul>
  
  ### Tipe Instance Amazon EC2
<p align="justify"> 
Setelah mempelajari tentang EC2 instance dan peran pentingnya di AWS, mari kita bahas perkara berbagai tipe instance yang tersedia. Pikirkan kembali analogi kita soal kedai kopi, Anda mungkin ingat bahwa EC2 instance itu seperti pegawai di kedai kopi. Mereka melayani permintaan client.</br>
Jika ingin memiliki kedai kopi yang mampu melayani banyak pelanggan, maka kita membutuhkan banyak pegawai, bukan? Tentunya para pegawai tersebut tak bisa semuanya berperan sebagai kasir. Harus ada seseorang yang membuat minuman, mengurusi makanan, dan mungkin yang dapat membuat seni latte keren agar pelanggan suka.</br>
Seperti bisnis yang lain, ada berbagai tugas khusus yang perlu diselesaikan dan kerap kali membutuhkan keahlian yang berbeda-beda. Jika ingin bisnis kita beroperasi seefisien mungkin, maka pastikan karyawan memiliki keahlian yang sesuai dengan peran mereka.</br>
Di kedai kopi kita memiliki berbagai jenis karyawan beserta perannya. Sama halnya dengan itu, AWS pun memiliki berbagai tipe EC2 instance yang dapat Anda jalankan dan terapkan ke dalam lingkungan AWS Anda.</br>
Setiap tipe instance dikelompokkan dalam satu instance family (keluarga instance) dan dioptimalkan untuk jenis tugas tertentu. Tipe instance menawarkan berbagai kombinasi dari kapasitas CPU, memori, penyimpanan, jaringan, serta memberi Anda fleksibilitas untuk memilih kombinasi sumber daya yang sesuai untuk aplikasi Anda.</br>
Instance family di Amazon EC2 memiliki fungsi yang berbeda-beda. Di antaranya ada general purpose, compute optimized, memory optimized, accelerated computing (komputasi terakselerasi), dan storage optimized. Berikut uraiannya:</p>

<ul align="justify"><li><b>General purpose instances (Instance tujuan umum)</b></br>
Tipe ini memberikan keseimbangan yang baik dari segi sumber daya komputasi, memori, dan jaringan. Selain itu, opsi ini juga dapat digunakan untuk berbagai beban kerja yang beragam seperti server aplikasi web atau repositori kode.</li>

<li><b>Compute optimized instances (Instance teroptimasi untuk komputasi)</b></br>
Tipe yang satu ini ideal untuk tugas komputasi yang intensif dan berpusat pada prosesor dengan performa tinggi, seperti server game, HPC (high-performance computing/komputasi dengan performa tinggi), atau bahkan pemodelan ilmiah.</br>
Anda juga bisa menggunakan tipe compute optimized instances untuk beban kerja batch processing yang membutuhkan banyak proses transaksi di satu grup.</li>
<li><b>Memory optimized instances (Instance teroptimasi untuk memori)</b></br>
Opsi ini didesain untuk memberikan performa tinggi untuk beban kerja yang memproses kumpulan data besar di dalam memori, seperti relasional dan nonrelasional database atau HPC (high-performance computing).</li>

<li><b>Accelerated computing instances (Instance terakselerasi untuk komputasi)</b></br>
Tipe ini menggunakan perangkat keras akselerator untuk menjalankan beberapa fungsi secara lebih efisien dibandingkan dengan perangkat lunak yang berjalan pada CPU. Contohnya adalah penghitungan bilangan floating-point, pemrosesan grafik, dan data pattern matching (pencocokan pola data).</li>

<li><b>Storage optimized instance (Instance teroptimasi untuk penyimpanan)</b></br>
Opsi ini didesain untuk beban kerja yang membutuhkan akses read (baca) dan write (tulis) yang tinggi dan berurutan untuk kumpulan data yang besar di penyimpanan lokal.

Contoh beban kerja yang sesuai untuk tipe ini mencakup sistem file terdistribusi, aplikasi data warehousing (gudang data), dan sistem online transaction processing (OLTP) berfrekuensi tinggi.</li></ul>
<p align="justify"> 
Dalam komputasi, istilah input/output operation per second (IOPS) adalah metrik yang mengukur kinerja perangkat penyimpanan. Ini menunjukkan berapa banyak operasi input atau output yang dapat dilakukan oleh perangkat dalam satu detik.</br>
Singkatnya, Anda dapat menganggap operasi input sebagai data yang dimasukkan ke dalam sistem, seperti data yang dimasukkan ke dalam database. Sedangkan operasi output adalah data yang dihasilkan oleh sistem. Contoh output adalah hasil analitik yang dilakukan pada data dalam database.</br>
Jika Anda memiliki aplikasi yang memerlukan IOPS tinggi, storage optimized instance dapat memberikan kinerja yang lebih baik dibandingkan dengan tipe lain yang tak teroptimasi untuk jenis kasus penggunaan ini.</br>
Jika dianalogikan ke dalam skenario kedai kopi, kasir itu akan menjadi memory optimized instance, barista menjadi compute optimized instance, dan si pembuat seni pada latte adalah accelerated computing instance.
  </p>
  <p align="justify"> 
  AWS memiliki beberapa pilihan penagihan terkait Amazon EC2. Di antaranya adalah:</p>

<ul align="justify"><li><b>On-Demand (Sesuai Permintaan)</b></br>
Opsi ini adalah yang paling dikenal, yaitu On-Demand. Anda hanya membayar selama instance berjalan--bisa per jam atau per detik--tergantung pada tipe instance dan sistem operasi yang Anda pilih.</br>
On-Demand sangat ideal untuk penggunaan jangka pendek, pengembangan dan pengujian aplikasi, serta beban kerja yang tidak dapat diprediksi dan diinterupsi. Selain itu, model harga ini juga biasa digunakan untuk yang baru memulai, menguji beban kerja, sekadar bereksperimen, atau mendapatkan rata-rata dasar pemakaian instance.</br>
Tak perlu kontrak, komitmen jangka panjang, pembayaran di muka, atau komunikasi dengan AWS sebelumnya untuk menggunakan pilihan penagihan yang satu ini.</br></li>
<li><b>Savings Plans (Rencana Tabungan)</b></br>
Savings Plans memungkinkan Anda mengurangi biaya komputasi dengan berkomitmen terhadap jumlah dolar per jam yang keluar dan penggunaan komputasi yang konsisten untuk jangka waktu 1 atau 3 tahun. Setiap penggunaan di luar itu akan dikenakan tarif On-Demand biasa. Oleh karena itu, model penetapan harga ini dapat memberikan penghematan hingga 72% pada penggunaan komputasi AWS Anda terlepas dari instance family (keluarga instance), ukuran, OS, tenancy (penyewaan), atau region AWS.</br>
Model Ini juga berlaku untuk penggunaan AWS Fargate dan AWS Lambda yang merupakan opsi komputasi tanpa server yang akan kita bahas nanti.Nanti di kelas ini kita akan meninjau tentang AWS Cost Explorer, yaitu layanan yang memungkinkan Anda untuk memvisualisasikan, memahami, serta mengelola biaya dan penggunaan AWS Anda dari waktu ke waktu.</br>
Jika Anda sedang mempertimbangkan opsi Savings Plans, AWS Cost Explorer dapat menganalisis penggunaan Amazon EC2 Anda selama 7, 30, atau 60 hari terakhir. AWS Cost Explorer juga memberikan rekomendasi yang disesuaikan untuk Savings Plans. Rekomendasi ini dapat memperkirakan seberapa banyak Anda dapat menghemat biaya bulanan berdasarkan penggunaan Amazon EC2 sebelumnya dan jumlah komitmen per jam dalam 1 atau 3 tahun.</li>
<li><b>Reserved Instances (Instance Terpesan)</b></br>
Reserved Instances menawarkan diskon penagihan yang diterapkan untuk instance On-Demand dengan berkomitmen terhadap tingkat penggunaan untuk jangka waktu 1 atau 3 tahun.</br>
Ada beberapa opsi yang tersedia: Standard Reserved dan Convertible Reserved Instances (Instance Terpesan Standar dan Terpesan Konvertibel) untuk jangka waktu 1 atau 3 tahun. Dan juga tersedia Scheduled Reserved Instance (Instance Terpesan Terjadwal) untuk jangka waktu 1 tahun saja. Opsi ini cocok untuk beban kerja dengan kondisi yang stabil atau dapat diprediksi. Reserved Instance menawarkan diskon hingga 75% dibandingkan dengan opsi On-Demand.</br>
</li></ul>
Terdapat tiga opsi pembayaran pada Reserved Instances: 
<ul align="justify"><li>All upfront (semua di muka), yaitu Anda membayarnya secara penuh saat Anda berkomitmen.</li>
<li>Partial upfront (sebagian di muka), di mana Anda membayar sebagian di awal.</li>
<li>No upfront (tanpa uang muka), di mana Anda tak membayar apa pun di muka.</li></ul>
<p align="justify">
Ketika Reserved Instance berakhir, Anda tetap bisa menggunakan Amazon EC2 instance tanpa gangguan. Namun akan dikenai tarif On-Demand hingga Anda menghentikannya atau membeli. Reserved Instance baru yang sesuai dengan atribut instance (tipe instance, region, tenancy (penyewaan), dan platform). </p>
<ul align="justify"><li><b>Spot Instances (Instance Spot)</b></br>
Spot Instances menggunakan kapasitas komputasi Amazon EC2 yang tak terpakai dan menawarkan penghematan biaya hingga 90% dari harga On-Demand. Opsi ini sangat ideal untuk beban kerja dengan waktu mulai dan akhir yang fleksibel dan tak masalah dengan interupsi.</br>
Jika Anda mengajukan Spot Instances dan kapasitas Amazon EC2 sedang tersedia, maka instance akan diluncurkan. Namun jika tidak, permintaan akan gagal sampai kapasitas tersedia kembali.</br>
Setelah Anda meluncurkan Spot Instances, AWS dapat mengklaim kembali instance tersebut kapan pun ketika mereka membutuhkannya.</br>
AWS akan memberikan waktu peringatan dua menit sebelumnya untuk Anda menyelesaikan pekerjaan. Anda selalu dapat melanjutkannya nanti jika perlu. Jadi, saat memilih opsi ini, pastikan beban kerja Anda dapat menerima interupsi.</br>
<li><b>Dedicated Hosts (Host Khusus)</b></br>
Dedicated Hosts merupakan server fisik dari kapasitas Amazon EC2 instance yang didedikasikan sepenuhnya untuk Anda gunakan.</br>
Opsi ini biasanya digunakan untuk memenuhi persyaratan compliance (kepatuhan) tertentu dan tidak ada orang lain yang akan berbagi sewa dari server fisik tersebut.</br>
Pada opsi ini Anda dapat menggunakan lisensi perangkat lunak per-socket, per-core, atau per-VM yang Anda punya untuk membantu menjaga persyaratan lisensi yang terikat dengan server.</br>
Itulah mengenai opsi harga pada Amazon EC2. Anda bisa memilih opsi apa pun tergantung dengan kasus penggunaannya. Jika Anda memiliki beban kerja yang tak masalah dengan interupsi, pilihlah Spot Instances. Atau Anda dapat menghemat dengan melakukan pembayaran lebih awal dan mengunci minimum tingkat penggunaan dengan Reserved Instance.</br>
<p align="justify">Dari semua opsi harga Amazon EC2 yang telah dibahas, opsi Dedicated Hosts adalah yang paling mahal.</br></br>
<b>Penyesuaian Kapasitas Amazon EC2</b></br></br>
Sampai sini, kita sudah memiliki pemahaman tentang dasar-dasar Amazon EC2 dan bagaimana itu dapat membantu kita dalam menangani kebutuhan komputasi apa pun, seperti membuat kopi di skenario kedai kopi kita. Minuman kopi mewakili apa pun yang dapat dihasilkan oleh instance Anda. Di modul ini kita akan berbincang mengenai manfaat utama lainnya dari AWS, yaitu skalabilitas dan elastisitas. Dua hal ini mengacu pada bagaimana kapasitas dapat bertambah dan berkurang sesuai kebutuhan. Itulah yang menjadi dilema jika menggunakan data center on-premise. Jika Anda memiliki bisnis seperti 99% dari semua bisnis di dunia, maka pastinya beban kerja aplikasi Anda bervariasi dari waktu ke waktu. Ada kalanya Anda mengalami masa-masa sibuk, ada juga di mana aplikasi Anda sepi.</br></br>
Jika Anda menggunakan data center on-premise, maka akan muncul satu pertanyaan yang selalu mencemaskan, “Berapa tepatnya jumlah perangkat keras yang harus dibeli?” Kalau Anda membelinya sesuai dengan jumlah penggunaan rata-rata, maka tidak akan terjadi pemborosan biaya. Namun sayangnya, ketika beban kerja melonjak, Anda tak akan memiliki perangkat keras yang cukup untuk melayani pelanggan. Akan banyak keluhan yang datang dari pelanggan karena mereka kesulitan mengakses aplikasi Anda. Nah, bagaimana jika Anda membeli perangkat keras melebihi beban kerja tertinggi dan berharap semua berjalan dengan lancar? Hmm. Mungkin pelanggan Anda akan senang. Tapi Anda akan memiliki sumber daya yang menganggur hampir sepanjang tahun, tentu ini akan terbuang sia-sia. Anda tak ingin terjebak dengan mereka, bukan?</br></br>
Jadi, bagaimana menyelesaikan masalah ini di on-premise? Ups. Tidak bisa. Namun jangan khawatir! Itulah kenapa kita belajar mengenai AWS di kelas ini. Sebenarnya dengan AWS, Anda dapat mengatur beban kerja berdasarkan kondisi yang Anda tentukan agar sesuai dengan permintaan. Nah, sekarang pelanggan Anda akan senang karena mereka selalu bisa mengakses aplikasi Anda. Anda pun akan bahagia karena tak lagi harus berkutat dengan prediksi dan biaya yang besar di awal. Itulah sedikit gambaran mengenai penyesuaian kapasitas alias scaling--selebihnya kita akan sering menggunakan kata scaling. Lalu, bagaimana cara kerjanya di AWS? Mari kita sangkut pautkan dengan skenario kedai kopi.</br></br>
Di kedai kopi kita menggunakan decoupled system (sistem yang terpisah). Artinya, setiap pegawai tidak melakukan semua pekerjaan sendiri. Seorang kasir hanya bertugas untuk menerima pesanan. Dan barista bertanggung jawab untuk membuat minuman. Nah, masalah pertama yang harus kita pecahkan adalah membuat rencana jika suatu saat terjadi bencana. Ada kutipan hebat dari Werner Vogels--VP dan CTO di Amazon--yang mengatakan, "Semuanya gagal setiap saat, jadi rencanakan kegagalan sehingga tidak ada yang gagal." Dengan kata lain, tanyakan pada diri sendiri apa yang akan terjadi jika kita kehilangan instance kasir di kedai kopi? Mungkin, kita tidak dapat melayani pelanggan hingga instance lain aktif dan lanjut bekerja.</br></br>
AWS membuatnya sangat sederhana. Dengan menggunakan metode terprogram yang sama seperti instance kasir yang asli, kita dapat membuat kasir kedua. Sehingga, jika salah satu instance tersebut mengalami kegagalan, kita memiliki instance lain yang sudah berada di garis depan dan siap menerima pesanan.</br></br>
Dengan begitu, pelanggan tak akan pernah kehilangan kasir. Hal yang sama pun bisa Anda lakukan terhadap instance barista jika Anda mau. Nah, sekarang kita memiliki sistem yang highly available (sangat tersedia) tanpa satu pun titik celah kegagalan. Selama jumlah pelanggan yang ada di antrean selaras dengan kapasitas instance, kita baik-baik saja.</br></br>
Tapi, kita semua tahu bahwa jumlah pelanggan yang sedang mengantre tak dapat diprediksi, bukan? Jadi, mari kita lihat apa yang akan terjadi ketika kita memiliki banyak pelanggan, yaitu dengan peningkatan kapasitas berdasarkan permintaan. Mari kita bahas apa yang sudah kita singgung di awal modul, tentang skalabilitas. Skalabilitas berarti kapasitas dari arsitektur Anda dapat merespons terhadap perubahan permintaan dengan melakukan scaling out atau scaling in--keduanya akan kita bahas nanti. Anda cukup membayar sumber daya yang Anda gunakan dan tak perlu lagi khawatir akan kekurangan kapasitas komputasi untuk memenuhi kebutuhan Anda. Jika ingin proses scaling terjadi secara otomatis untuk instance EC2, maka layanan AWS yang tepat adalah Amazon EC2 Auto Scaling.</p>
<p align="justify"><b>Amazon EC2 Auto Scaling</b></br>
Pernahkah Anda mencoba mengakses sebuah website namun halaman tersebut tak dapat memuat info dan malah sering kali menunjukkan eror seperti timeout (kehabisan waktu). Itu artinya, website tersebut terlalu banyak menerima permintaan masuk sehingga tak dapat menanganinya lagi. Maka dari itu, hadirlah solusi Amazon EC2 Auto Scaling.</br></br>
Amazon EC2 Auto Scaling memudahkan Anda untuk menambah atau menghapus Amazon EC2 instances secara otomatis sesuai kebutuhan. Dengan begitu, Anda dapat membuat aplikasi selalu tersedia. Dengan menggunakan Amazon EC2 Auto Scaling, Anda dapat menggunakan dua pendekatan:</p>

<ul align="justify"><li><b>Dynamic scaling</b>, yaitu merespons terhadap perubahan permintaan.</li>
<li><b>Predictive scaling</b>, yaitu secara otomatis menjadwalkan jumlah Amazon EC2 instances yang tepat berdasarkan prediksi permintaan.</li></ul>

<p align="justify">Catatan: Anda pun dapat menggunakan dynamic scaling dan predictive scaling secara bersamaan agar dapat melakukan scaling arsitektur dengan lebih cepat. Sekarang, mari kita belajar tentang beberapa cara untuk menangani permintaan yang melonjak. Anda dapat melakukan scaling up/vertical scaling atau scaling out/horizontal scaling.</br></br>
<b>Scaling up</b> artinya menambahkan lebih banyak daya pada mesin yang sedang berjalan. Saat pelanggan kedai kopi Anda semakin banyak, instance kasir yang menjadi lebih besar bukanlah solusinya karena kasir tetap tidak dapat menerima pesanan pelanggan dengan lebih cepat. Karena terkadang, kecepatan menerima pesanan itu tergantung pada pelanggan, bukan kasir.</br></br>
Lantas apa solusinya? Tentu dengan memperbanyak pegawai!</br></br>
<b>Scaling Out</b></p>
<p align="justify">Sederhananya, scaling out artinya menambahkan lebih banyak instance agar dapat menangani permintaan.Coba perhatikan gambar di atas. Kenapa terdapat lebih banyak instance kasir daripada instance barista? Nah, dalam kasus ini, jumlah tugas yang dapat diselesaikan oleh instance barista masih dapat ditangani dengan baik daripada instance kasir. Salah satu keunggulan dengan decoupling the system (memisahkan sistem) adalah Anda bisa mendapatkan jumlah daya yang tepat untuk setiap bagian dari proses daripada harus menyediakan terlalu banyak instance. Oke, sepertinya kita baru saja membereskan antrean tersebut. Saat kedai kopi Anda sudah sepi pelanggan, Anda dapat menyuruh para pegawai tambahan tersebut pulang atau menghentikan instance-nya.</br></br>
Catatan: Selain scaling up dan scaling out, ada juga istilah scaling down dan scaling in. Dua hal ini adalah kebalikan dari yang telah kita bahas. Scaling down berarti Anda membuat daya komputasi menjadi lebih kecil, sementara scaling in berarti Anda mengurangi jumlah instance.</br></br>
Kesimpulannya, dengan Amazon EC2 Auto Scaling Anda dapat menambahkan instance sesuai permintaan kemudian menonaktifkannya saat tak memerlukannya lagi. Ini berarti Anda akan selalu memiliki jumlah instance yang tepat setiap saat.</br></br>
<b>Auto Scaling Group</b></br>
Di cloud, komputasi adalah sumber daya yang terprogram sehingga Anda dapat mengambil pendekatan yang lebih fleksibel untuk masalah scaling (penyesuaian kapasitas).Nah, untuk melakukan scaling, kita perlu mengonfigurasi ukuran dari Auto Scaling group (grup Auto Scaling)--kumpulan Amazon EC2 instance untuk tujuan scaling dan manajemen secara otomatis. Untuk mengaturnya, Anda perlu menentukan berbagai jenis konfigurasi, seperti minimum capacity (kapasitas minimum), desired capacity (kapasitas yang diinginkan), dan maximum capacity (kapasitas maksimum).</br></br>
<b>Minimum capacity</b></br>
Minimum capacity alias kapasitas minimum adalah jumlah Amazon EC2 instance yang diluncurkan segera setelah Anda membuat Auto Scaling group. Ambil contoh kita menentukan minimumnya 1. Ini berarti setidaknya harus ada 1 Amazon EC2 instance yang berjalan setiap saat.</br>
<b>Desired capacity</b></br>
Selain itu, Anda dapat mengisi desired capacity dengan 2 Amazon EC2 instance meskipun aplikasi Anda hanya memerlukan minimal 1 instance untuk dijalankan.</br></br>
Catatan: Jika Anda tidak menentukan jumlah desired capacity dalam Auto Scaling group, maka otomatis akan diatur menjadi default ke minimum capacity Anda.</br></br>
<b>Maximum capacity</b></br>
Konfigurasi ketiga yang dapat Anda atur adalah maximum capacity. Misalnya, Anda dapat mengonfigurasi Auto Scaling group untuk menyesuaikan dengan permintaan yang melonjak namun maksimum hanya untuk 4 Amazon EC2 instance. Karena Amazon EC2 Auto Scaling menggunakan Amazon EC2 instance, Anda hanya membayar sesuai yang Anda gunakan. Tak hanya itu, Anda pun akan memiliki arsitektur yang hemat biaya dan dapat memberikan pengalaman terbaik kepada pelanggan.</br></br>
<b>Mengarahkan Traffic dengan Elastic Load Balancing</b></br>
Di modul sebelumnya kita telah berhasil memecahkan masalah scaling (penyesuaian kapasitas) dengan Amazon EC2 Auto Scaling. Tapi kita masih punya satu masalah lainnya terkait traffic (lalu lintas).</br></br>
Mari lihat situasinya di skenario kedai kopi. Sekarang kita memiliki 3 instance kasir yang disiapkan untuk menangani masalah ramainya pelanggan.</br></br>
Namun anehnya, kebanyakan dari mereka malah mengantre di satu instance kasir saja sehingga menyebabkan distribusi pelanggan yang tidak merata. Ini membuat instance kasir yang lain hanya terdiam dan tak melakukan apa pun sambil terus menunggu pesanan.</br></br>
Masalah ini bisa terjadi karena saat pelanggan tersebut datang, mereka tak yakin harus menuju ke kasir yang mana.</br>
Lantas apa solusinya?</br>
Akan sangat membantu jika kita mempekerjakan satu pegawai yang bertugas untuk menerima dan mengonfirmasi reservasi dari para pelanggan saat masuk ke kedai kopi. Peran semacam ini biasa disebut dengan nama host--bukan mesin fisik yang kita bahas sebelumnya ya--dan biasanya ditempatkan di depan pintu kedai kopi.</br>
Host akan senantiasa mengarahkan setiap pelanggan yang baru masuk untuk berbaris di kasir dengan antrean terpendek. Dengan demikian, antrean pun akan merata di seluruh kasir sehingga pelanggan dapat terlayani dengan efisien.</br>
Ide yang sama pun berlaku di lingkungan AWS. Katakanlah Anda memiliki beberapa EC2 instance yang menjalankan program serupa. Anda perlu mengarahkan setiap permintaan yang masuk untuk menuju ke EC2 instance tertentu. Anda juga harus memastikan bahwa distribusi beban kerja merata di seluruh EC2 instance sehingga tak ada satu instance pun yang menganggur.</br>
Proses dari apa yang sejak tadi kita bincangkan ini disebut dengan load balancing (menyeimbangkan beban). Sedangkan aplikasi yang dapat menerima permintaan lalu mengarahkannya ke instance untuk diproses disebut dengan load balancer (penyeimbang beban).</br>
Load balancer bertindak sebagai satu titik kontak untuk semua traffic web yang masuk ke Auto Scaling group Anda. Ini berarti saat Anda menambah atau menghapus Amazon EC2 instance sebagai respons terhadap jumlah traffic yang masuk, permintaan ini diarahkan ke load balancer terlebih dahulu. Barulah kemudian permintaan tersebut disebar ke berbagai sumber daya yang akan menanganinya.</br></br>
<b>Elastic Load Balancing</b></br>
AWS memiliki layanan load balancer yang berkinerja tinggi, hemat biaya, highly available (sangat tersedia), dan dapat diskalakan secara otomatis. Tak usah Anda menginstal, mengelola, memperbarui, melakukan scaling, menangani kegagalan, dan ketersediaan layanannya. AWS yang mengurus itu semua.</br></br>
Perkenalkan Elastic Load Balancing (ELB), yaitu layanan AWS yang secara otomatis mendistribusikan traffic aplikasi yang masuk ke berbagai sumber daya, seperti Amazon EC2 instance.</br></br>
<b>Elastic Load Balancing</b> merupakan salah satu layanan terkelola pertama yang akan kita telaah dalam kelas ini. Layanan ini dirancang untuk mengatasi undifferentiated heavy lifting--telah kita bahas di modul 1--dari load balancing.</br></br>
Sebagai permulaan, Elastic Load Balancing adalah regional construct (konstruksi regional). Ini berarti ELB berjalan di tingkat Region, bukan pada individu EC2 instance sehingga membuatnya highly available secara otomatis.</br></br>
ELB dapat diskalakan secara otomatis sehingga mampu menangani kepadatan traffic tanpa berdampak pada biaya per jamnya. Elastic Load Balancing dapat bekerja sama dengan Amazon EC2 Auto Scaling untuk membantu memastikan aplikasi yang berjalan di Amazon EC2 dapat memberikan kinerja dan ketersediaan tinggi.</br></br>
Mari kita ilustrasikan penggunaan ELB yang berkolaborasi bersama layanan Amazon EC2 Auto Scaling dalam menangani traffic. Anggaplah di suatu pagi aplikasi Anda memiliki traffic yang normal. Lalu di siang hari, Anda mengadakan promo flash sale secara besar-besaran di aplikasi bisnis Anda, tak lama kemudian lalu lintas pun semakin meningkat.</br></br>
Saat traffic membanjiri aplikasi Anda, EC2 instance akan melakukan scaling out. Saat instance siap, Amazon EC2 Auto Scaling akan memberi tahu Elastic Load Balancing bahwa ia siap untuk menangani traffic.</br></br>
Katakanlah malam tiba dan promo flash sale pun berakhir. Ini membuat traffic pada aplikasi Anda semakin berkurang sehingga Amazon EC2 Auto Scaling harus melakukan scaling in. Artinya, ada beberapa EC2 instance yang akan diakhiri.</br></br>
Tapi sebelum itu, ELB akan berhenti mengirimkan traffic kepada instance yang akan diakhiri tersebut dan menunggu hingga permintaan selesai ditangani. Setelah selesai, barulah Amazon EC2 Auto Scaling bisa mengakhiri instance tanpa mengganggu aktivitas pelanggan yang ada.</br></br>
Selain untuk lalu lintas eksternal, Anda juga bisa menggunakan ELB untuk traffic di dalam arsitektur AWS. Mari kita lihat ilustrasikan bagaimana ELB berperan menangani komunikasi untuk setiap instance di antara bidang pemesanan dan produksi.</p>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/202103101509453847705d5cc224526c099435179c775d.png"></p>


<p align="justify">Sebelum menggunakan ELB, setiap instance di bidang pemesanan mengetahui seluruh instance produksi. Jadi, jika ada instance baru di bidang produksi, dia harus memberi tahu semua instance pemesanan bahwa sekarang dirinya dapat menerima traffic. Huh! Ini cukup rumit ya walau hanya ada 4 instance.</br></br>
Sekarang bayangkan jika Anda memiliki ratusan instance di kedua bidang tersebut. Ampun! Tak sanggup lagi Anda bayangkan akan betapa kacaunya. Dengan kompleksitas seperti itu, mustahil rasanya membuat mereka tetap terhubung secara efisien.</br></br>
Nah, di momen inilah ELB hadir memberikan solusi terbaik sehingga sekarang kita bisa menuntaskan kacau balau traffic pada bidang produksi. Mari kita pecahkan!</p>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210310151115c5b1a9bc18cbf2e57725f0e691fe6787.png"></p>

<p align="justify">Kita telah menyinggung di awal bahwa ELB bersifat regional. Ini membuat setiap instance di bidang pemesanan dapat menggunakan satu URL saja dan ELB pun akan mengarahkannya ke instance produksi yang memiliki permintaan paling sedikit.</br></br>
Lantas, bagaimana jika ada instance baru di bidang produksi? Mudah. Instance tersebut cukup memberi tahu ELB bahwa dirinya siap menerima traffic. Instance di bidang pemesanan tak perlu tahu dan tak akan peduli ada berapa banyak instance yang berjalan di bidang produksi. Sekali lagi, inilah yang dinamakan decoupled architecture (arsitektur yang terpisah).</br></br>
Ada lebih banyak lagi hal yang dapat dilakukan oleh ELB yang nanti akan kita pelajari. Kesimpulannya, pilihlah layanan yang tepat untuk tugas yang tepat. Itulah salah satu alasan mengapa AWS menawarkan begitu banyak layanan yang beragam.</br></br>
<b>Messaging dan Queueing</b></br>
Mari kita membahas tentang perpesanan dan antrean. Di skenario kedai kopi, ada dua jenis peran: kasir--yang menerima pesanan dari pelanggan--dan barista--yang membuat pesanan.</br></br>
Proses interaksi di antara keduanya adalah seperti ini: kasir mengambil pesanan dari pelanggan, menuliskannya dengan pena dan kertas, dan mengirimkannya ke barista. Kemudian, barista mengambil kertas tersebut dan membuat pesanan.</br></br>
Saat pesanan berikutnya masuk, prosesnya berulang. Proses ini akan bekerja dengan baik selama kasir dan barista selaras. Tetapi, apa yang akan terjadi jika kasir ingin menyerahkan pesanan pelanggan namun barista sedang istirahat atau sibuk dengan pesanan lain?</br></br>
Kasir tersebut akan berhenti melayani sampai barista siap mengambil pesanan. Pada titik tertentu pesanan mungkin akan dibatalkan dan kasir pun melayani pelanggan berikutnya.</br></br>
Coba amati! Kasus tersebut adalah proses yang tak sempurna. Ini karena jika kasir atau barista tidak sinkron, maka keseluruhan prosesnya akan terganggu sehingga menyebabkan lambannya penerimaan pesanan. Bahkan bisa sampai mengakibatkan kegagalan penyelesaian pesanan. Ah! Tentu Anda tak ingin ini terjadi, bukan?</br></br>
Jadi, bagaimana jalan keluar yang paling efektif untuk kasus ini?</p>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210328150805f01e8ad52dfd3a28323341fc78550512.png"></p>


<p align="justify">Solusi terbaik untuk menangani masalah ini adalah dengan menyediakan semacam buffer (antrean pesanan) ke dalam sistem. Daripada menyerahkan pesanan langsung ke barista, kasir akan menaruhnya ke semacam papan pesanan. Barista akan memeriksa buffer tersebut dan membuat minuman sesuai pesanan.</br></br>
Setelah minuman tersaji dan memberikannya kepada pelanggan, barista akan menghapus pesanan yang sudah selesai tersebut dari buffer. Dengan begitu, selagi barista menyiapkan minuman, kasir dapat terus menerima pesanan baru dan menambahkannya ke buffer.</br></br>
Ide dari menempatkan pesan ke dalam buffer disebut messaging dan queueing. Sama seperti kasir yang mengirimkan pesanan ke barista, aplikasi saling mengirim pesan untuk berkomunikasi. Ketika aplikasi berkomunikasi secara langsung seperti kasus kasir dan barista kita sebelumnya, maka itu disebut dengan tightly coupled architecture.</br></br>
Ciri khas dari arsitektur yang tightly coupled adalah jika ada satu komponen yang gagal atau berubah, maka kegagalan ini memicu masalah untuk komponen lain atau bahkan keseluruhan sistem.</br></br>
Misalnya kita punya aplikasi A yang mengirimkan pesan langsung ke aplikasi B. Jika aplikasi B mengalami kegagalan dan tak dapat menerima pesan tersebut, maka aplikasi A pun akan terkena eror juga.</br></br>
Desain aplikasi seperti ini dapat dianggap sebagai pendekatan monolithic application alias aplikasi monolitik, yaitu saat berbagai komponen digabungkan menjadi satu kesatuan.</p>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/2021032815083253456c3781b8b931323f4603d2b792e5.png"></p>


<p align="justify">Nah, untuk mengatasi masalah ini kita harus membuat arsitektur yang lebih andal dengan loosely coupled architecture. Karakter dari arsitektur ini adalah jika satu komponen gagal, maka komponen tersebut akan diisolasi sehingga tak akan menyebabkan kegagalan beruntun ke seluruh sistem. Lebih baik yang ini, bukan?</br></br>
Sama seperti di kedai kopi yang menyertakan buffer di antara kasir dan barista, kita juga dapat menggunakan komponen yang serupa, yaitu message queue (antrean pesan).Pesan dikirim ke antrean oleh aplikasi A dan diproses oleh aplikasi B. Jika aplikasi B gagal, aplikasi A tidak mengalami gangguan apa pun. Pesan yang dikirim masih dapat dikirim ke antrean dan akan tetap berada di sana sampai akhirnya diproses.</br></br>
Desain aplikasi semacam ini merupakan pendekatan dari microservice (layanan mikro), yaitu saat komponen dibuat menjadi loosely coupled sehingga dapat dikembangkan, di-deploy (diterapkan), dan dikelola secara independen. Setiap komponen mempunyai tugasnya masing-masing dan juga dapat berkomunikasi satu sama lain.</p>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/202103281508458ed122e388f934023602b3bacd6c04dd.png"></p>


<p align="justify">Oke, jadi layanan apa yang dapat kita gunakan di AWS?</br></br>
Perkenalkan dua layanan AWS yang dapat membantu Anda dalam meraih arsitektur yang loosely coupled: Amazon Simple Queue Service (Amazon SQS) dan Amazon Simple Notification Service (Amazon SNS).</br></br>
Tetapi sebelum kita menyelami keduanya, marilah memesan sebuah kopi terlebih dahulu di website kedai kopi kita. Sudah? Oke, kita tunggu saja. Seharusnya kita akan mendapatkan notifikasi saat pesanan itu siap. Lanjut!</br></br>
<b>Amazon Simple Queue Service (Amazon SQS)</b></br>
Amazon Simple Queue Service (Amazon SQS) memungkinkan Anda untuk mengirim, menyimpan, dan menerima pesan antar komponen perangkat lunak dengan volume berapa pun tanpa perlu khawatir akan kehilangan pesan tersebut atau membutuhkan layanan lain untuk menyediakan pesan. Data yang terkandung di dalam pesan disebut payload dan itu dilindungi hingga terkirim.</br></br>
Amazon SQS queue adalah tempat di mana pesan ditaruh sampai diproses. Cara kerjanya adalah aplikasi A akan mengirim sebuah pesan ke dalam queue lalu aplikasi B akan mengambilnya, memprosesnya, dan kemudian menghapusnya dari antrean.</br></br>
AWS mengelola infrastruktur yang mendasarinya sehingga layanan ini dapat otomatis diskalakan, andal, serta mudah dikonfigurasi dan digunakan. Jika Anda sukar memahaminya, bayangkan saja sebuah pesan sebagai sebuah pesanan kopi dan SQS queue adalah buffer, sebagaimana yang terdapat di skenario kedai kopi kita.</br></br>
<b>Amazon Simple Notification Service (Amazon SNS)</b></br>
Amazon Simple Notification Service (Amazon SNS) juga digunakan untuk mengirimkan pesan ke layanan. Bedanya, ia juga dapat mengirimkan pemberitahuan ke pelanggan.</br></br>
Proses tersebut dilakukan dengan cara yang berbeda, yaitu menggunakan model publish/subscribe alias pub/sub. Itu artinya Anda dapat membuat suatu saluran untuk menyampaikan pesan yang disebut dengan SNS topic. Jika ingin mempublikasikan pesan (publish), Anda bisa mengatur pelanggan (subscribers) yang akan menerima topik tersebut.</br></br>
Dalam praktiknya, Anda dapat mengirim satu pesan ke SNS topic yang kemudian akan menyebar ke semua subscribers dalam sekali jalan. Subscribers dapat berupa endpoint (titik akhir) layanan lain, seperti SQS queue, fungsi AWS Lambda--akan kita bahas nanti, dan juga server web.</br></br>
Selain itu, Amazon SNS dapat digunakan untuk menyebarkan notifikasi kepada pelanggan menggunakan push notification (pesan yang muncul di perangkat seluler), SMS, dan email.</br></br>
Nah, begitu juga dengan skenario kedai kopi. Kita dapat mengirimkan pemberitahuan kepada pelanggan ketika pesanan mereka sudah siap untuk diambil, bisa berupa SMS atau push notification.</br></br>
Wah! Sepertinya kopi yang telah kita pesan tadi sudah siap diambil. Apakah Anda menerima pemberitahuannya juga?</br></br>
<b>Studi Kasus: Amazon SNS</b></br>
Katakanlah Anda membuat suatu buletin di kedai kopi berupa pembaruan yang mencakup informasi kupon, trivia kopi, dan produk baru. Semua informasi ini dikelompokkan menjadi satu topik karena ini adalah buletin tunggal. Semua pelanggan yang berlangganan buletin menerima pembaruan tentang topik-topik tersebut.</br></br>
Tak lama kemudian, beberapa pelanggan Anda memberikan umpan balik bahwa mereka lebih suka menerima buletin terpisah hanya untuk topik tertentu saja, sesuai ketertarikan mereka. Anda pun mengabulkannya.</br></br>
Sekarang buletin di kedai kopi telah terbagi menjadi tiga: kupon, trivia kopi, dan produk baru. Pelanggan pun akan menerima buletin sesuai dengan topik tertentu yang mereka inginkan. Mereka dapat berlangganan satu topik atau beberapa topik sekaligus.</br></br>
Misalnya, pelanggan pertama hanya berlangganan topik kupon; pelanggan kedua hanya berlangganan topik trivia kopi; dan pelanggan ketiga berlangganan topik kopi trivia dan produk baru.</br></br>
Meskipun contoh dari kedai kopi ini melibatkan pelanggan yang merupakan manusia, di Amazon SNS, pelanggan/subscribers dapat berupa server web, alamat email, AWS Lambda function, atau beberapa opsi lainnya.</br></br>
<b>Layanan Komputasi Tambahan</b></br>
EC2 instance adalah mesin virtual yang dapat Anda gunakan di AWS. EC2 sangat ideal untuk semua jenis kasus penggunaan seperti menjalankan server web sederhana hingga menjalankan high performance computing clusters (klaster komputasi berkinerja tinggi).</br></br>
EC2 mengharuskan Anda untuk mengatur dan mengelola instance dari waktu ke waktu. Saat Anda menggunakan EC2, Anda bertanggung jawab untuk:</p>
<ul align="justify"><li>Melakukan patching (memperbaiki masalah dengan memperbarui program komputer) saat software package (paket perangkat lunak) yang baru tersedia.</li>
<li>Menyiapkan scaling (penyesuaian kapasitas).</li>
<li>Merancang aplikasi untuk dijalankan dengan cara yang highly available (sangat tersedia).</li></ul>
<p align="justify">Bahkan, jika Anda menggunakan data center on-premise, masih ada banyak hal lain yang harus Anda kelola.</br></br>
Lalu, bagaimana solusinya? Mari kita melangkah ke materi berikutnya.</p>
<p align="justify"> <b> Komputasi Serverless</b>
<p align="center"><img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210328150929cb2ea144cd42b31b5bf11cebf9d8c5a0.png"></p>

<p align="justify">Anda mungkin akan bertanya-tanya, “Apa ada layanan komputasi lain di AWS yang tak perlu berkutat dengan pengelolaan?”</br></br>
Di sinilah istilah serverless (tanpa server) hadir. Serverless berarti Anda tidak dapat melihat dan mengakses infrastruktur dasar yang menjalankan aplikasi Anda. Semua pengelolaan lingkungan yang mendasari penyediaan, scaling, high availability (ketersediaan tinggi), dan pemeliharaan sudah ditangani sehingga Anda bisa fokus pada aplikasi yang akan dijalankan.</br></br>
<b>AWS Lambda</b></br>
AWS menawarkan beberapa opsi komputasi serverless, salah satunya adalah AWS Lambda. AWS Lambda adalah layanan yang memungkinkan Anda untuk menjalankan kode tanpa harus membuat atau mengelola server.</br></br>
AWS Lambda dikelola sepenuhnya, dapat diskalakan secara otomatis, highly available (sangat tersedia), dan semua pemeliharaan dilakukan oleh AWS. Jika Anda memiliki 1 atau bahkan 1000 trigger (pemicu) yang masuk untuk memanggil function (fungsi), Lambda akan melakukan scaling terhadap function tersebut guna memenuhi permintaan.</br></br>
AWS Lambda dirancang untuk menjalankan kode di bawah 15 menit sehingga layanan ini tak cocok untuk proses yang berjalan lama seperti deep learning misalnya. Layanan Ini lebih ideal untuk pemrosesan cepat seperti web backend, penanganan permintaan, atau pemrosesan laporan pengeluaran yang mana hanya membutuhkan waktu kurang dari 15 menit.</p>
<p align="justify"><b>Cara Kerja AWS Lambda</b></p>
<p align="center">
  <img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/202103101558039c0a86159a918f024ca2ed53136af24d.png"></p>
<p align="justify">
Mungkin sempat terbayangkan oleh Anda, bagaimana AWS Lambda ini bekerja. Mari kita uraikan yuk.</p>

<ol align="justify" type='a'><li>Unggah kode Anda ke AWS Lambda.</li>
<li>Konfigurasikan kode Anda agar terpicu (trigger) dari sumber kejadian, seperti layanan AWS, aplikasi seluler, atau HTTP endpoint (titik akhir HTTP).</li>
<li>Kode berjalan hanya ketika mendapat trigger.</li>
<li>Cukup bayar sesuai waktu komputasi yang Anda gunakan. Misalnya, Anda mempunyai kode yang dapat mengubah ukuran gambar. Nah, Anda hanya akan membayar waktu komputasi yang digunakan untuk menjalankan fungsi pengubahan ukuran gambar saat ada yang mengunggah sebuah gambar baru.</li></ol>

<p align="justify">Jadi begitulah cara kerja AWS Lambda. Mari kita lanjutkan pembahasannya ke materi container.</br></br>
<b>Container</b></br>
Jika Anda belum cukup siap untuk menggunakan serverless atau memerlukan akses ke infrastrukturnya namun tetap menginginkan efisiensi dan portabilitas, Anda bisa mencoba layanan container (kontainer) seperti Amazon Elastic Container Service (Amazon ECS) dan Amazon Elastic Kubernetes Service (Amazon EKS). Kita akan menjabarkan ini nanti ya.</br></br>
Keduanya merupakan layanan container orchestration alias orkestrasi kontainer. Container dalam hal ini adalah Docker container. Apa itu?</br></br>
<b>Docker </b> adalah platform perangkat lunak populer yang menggunakan virtualisasi sistem operasi untuk memudahkan Anda dalam membangun, menguji, dan men-deploy (menerapkan) aplikasi dengan cepat. Sementara container menyediakan cara untuk mengemas kode, konfigurasi, dan dependensi aplikasi Anda ke dalam satu objek.</p>
<p align="center">
  <img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/20210310160357746e42a6aadc64fcd3b9c26f504d93e6.png"></p>
<p align="justify">
Container bekerja di atas EC2 instance dan berjalan secara terpisah satu sama lain. Cara kerja container serupa dengan mesin virtual, namun dalam kasus ini, host-nya (server) adalah EC2 instance.</br></br>
Saat menggunakan Docker container di AWS, Anda memerlukan proses untuk memulai, menyetop, memulai ulang, dan memantau container yang berjalan tidak hanya di 1 EC2 instance, melainkan beberapa yang disebut dengan cluster (klaster). Proses menggarap tugas-tugas inilah yang disebut dengan container orchestration dan tentu akan sangat sulit jika melakukannya sendiri. Layanan orkestrasi dibuat untuk membantu mengelola container Anda.</br></br>
<b>Studi Kasus: Container</b></br>
Misal developer aplikasi di suatu perusahaan memiliki infrastruktur komputer yang berbeda dengan staf operasi IT. Developer tersebut ingin memastikan bahwa lingkungan aplikasi tetap konsisten terlepas dari deployment-nya (penerapannya) sehingga dia pun menggunakan pendekatan container.</br></br>
Container membantu developer tersebut mengurangi waktu yang dihabiskan untuk debugging (proses mengidentifikasi dan memperbaiki eror) aplikasi dan mendiagnosis perbedaan dalam lingkungan komputasi. Saat menjalankan containerized application (aplikasi dalam container), penting untuk mempertimbangkan skalabilitas. Ini tergantung kepada setiap kasus penggunaan, Anda bisa saja: </p>
<ul align="justify"><li>Menggunakan satu host dengan banyak container.</li>
<li>Mengelola puluhan host dengan ratusan container.</li>
<li>Mengurus mungkin ratusan host dengan ribuan container.</li></ul>

<p align="justify">Dalam skala besar, bayangkan berapa lama waktu yang Anda butuhkan untuk memantau penggunaan memori, keamanan, logging (tindakan menyimpan log), dsb. Untuk itulah hadir layanan container orchestration (orkestrasi container) yang membantu Anda men-deploy (menerapkan), mengelola, dan men-scaling aplikasi dalam container. Selanjutnya, kita akan mempelajari tentang dua layanan yang menyediakan container orchestration: Amazon Elastic Container Service dan Amazon Elastic Kubernetes Service</br></br>
<b>Amazon Elastic Container Service (Amazon ECS)</b></br>
Amazon Elastic Container Service (Amazon ECS) adalah sistem manajemen container berkinerja tinggi yang dapat memungkinkan Anda untuk menjalankan dan melakukan scaling terhadap containerized application (aplikasi dalam container) di AWS. Amazon ECS mendukung Docker container. AWS mendukung penggunaan open-source Docker Community Edition and subscription-based Docker Enterprise Edition. Dan juga, dengan Amazon ECS, Anda dapat menggunakan panggilan API untuk meluncurkan dan menghentikan aplikasi yang mendukung Docker. API atau Application Programming Interface adalah perantara perangkat lunak yang memungkinkan dua aplikasi untuk berinteraksi satu sama lain. Kita tak akan membahas detailnya di sini. Jadi, mari lanjut ke materi berikutnya!</br></br>
<b>Amazon Elastic Kubernetes Service (Amazon EKS)</b></br>
Amazon Elastic Kubernetes Service (Amazon EKS) adalah layanan terkelola sepenuhnya yang dapat Anda gunakan untuk menjalankan Kubernetes di AWS.</br></br>
<b>Kubernetes</b> adalah perangkat lunak open-source (sumber terbuka) yang memungkinkan Anda untuk men-deploy (menerapkan) dan mengelola containerized application (aplikasi dalam container) dalam skala besar.</br></br>
AWS secara aktif bekerja sama dengan komunitas Kubernetes--yang mengelola Kubernetes. Saat fitur dan fungsionalitas baru dirilis untuk aplikasi Kubernetes, Anda dapat dengan mudah menerapkan pembaruan tersebut ke aplikasi Anda yang dikelola oleh Amazon EKS.</br></br>
<b>AWS Fargate</b></br>
Baik Amazon ECS dan Amazon EKS, keduanya berjalan di atas EC2. Tetapi jika Anda tak ingin sibuk mengurusi EC2, Anda dapat menggunakan platform komputasi lainnya yang disebut dengan AWS Fargate.</br></br>
AWS Fargate adalah platform komputasi serverless untuk Amazon ECS dan Amazon EKS. Saat menggunakan layanan ini, Anda tak perlu menyediakan atau mengelola server karena AWS Fargate yang mengelolanya untuk Anda.</br></br>
Dengan begitu, Anda dapat lebih fokus pada inovasi dan pengembangan aplikasi. Bahkan Anda membayar hanya untuk sumber daya yang diperlukan dalam menjalankan container.</br></br>
Masih bingung? Mari kita perjelas. Setiap layanan dapat Anda gunakan sesuai dengan kebutuhan.</p>
<ol align="justify" type='1'><li>Jika Anda ingin menjalankan aplikasi dan menginginkan akses penuh ke sistem operasinya seperti Linux atau Windows, Anda bisa menggunakan Amazon EC2.</li>
<li>Jika Anda ingin menjalankan fungsi yang berjalan singkat, aplikasi berbasis kejadian, dan Anda tak ingin mengelola infrastrukturnya sama sekali, gunakanlah layanan AWS Lambda.</li>
<li>Jika Anda ingin menjalankan beban kerja berbasis Docker container di AWS, langkah yang perlu Anda lalui adalah:</li>
<ol align="justify" type='a'><li>Anda harus memilih layanan orkestrasinya terlebih dahulu. Anda bisa menggunakan Amazon ECS atau Amazon EKS.</li>
<li>Setelah memilih alat orkestrasinya, kemudian Anda perlu menentukan platformnya. Anda dapat menjalankan container pada EC2 instance yang Anda kelola </li><li>sendiri atau dalam lingkungan serverless seperti AWS Fargate yang dikelola oleh AWS.</li></ol></ol>

<p align="justify" type='1'><b>Ikhtisar</b></br>
Tibalah kita di penghujung modul. Mari kita uraikan apa yang telah kita pelajari di modul ini:</p>
<ol align="justify" type='1'><li>Hal pertama yang kita pelajari di modul ini berkenaan dengan komputasi cloud dan apa saja yang ditawarkan AWS.
AWS mendefinisikan komputasi cloud sebagai penyajian sesuai permintaan (on-demand) sumber daya IT melalui internet dengan harga sesuai pemakaian (pay-as-you-go).</br>
Ini berarti Anda dapat membuat permintaan untuk sumber daya IT seperti komputasi, jaringan, penyimpanan, analitik, atau jenis sumber daya lainnya. Alih-alih membayar sumber daya tersebut di muka, Anda cukup membayarnya pada setiap akhir bulan.</li>
<li>AWS menawarkan banyak layanan dan kategori yang dapat Anda gunakan. Sejauh ini kita telah membahas beberapa layanan, salah satunya adalah tentang Amazon EC2. Dengan EC2, Anda dapat membuat dan menghapus server virtual secara dinamis yang disebut dengan EC2 instance.</li>
<li>Saat Anda meluncurkan EC2 instance, Anda dapat memilih instance family(keluarga instance) yang menentukan perangkat keras tempat instance tersebut berjalan. Sehingga, Anda dapat memiliki instance yang dibuat untuk tujuan tertentu. Kategorinya adalah:</li>
<ol align="justify" type='a'><li>General purpose (tujuan umum)</li>
<li>Compute optimized (teroptimasi untuk komputasi)</li>
<li>Memory optimized (teroptimasi untuk memori)</li>
<li>Accelerated computing (terakselerasi untuk komputasi)</li>
<li>Storage optimized (teroptimasi untuk penyimpanan).</li></ol>
<li>Selanjutnya, Anda dapat melakukan scaling EC2 instance baik secara vertikal--dengan mengubah ukuran instance--atau secara horizontal--dengan meluncurkan instance baru. Anda dapat mengatur horizontal scaling secara otomatis menggunakan Amazon EC2 Auto Scaling.</li>
<li>Setelah Anda melakukan scaling EC2 instance secara horizontal, Anda memerlukan sesuatu untuk mendistribusikan traffic yang masuk. Layanan yang dapat Anda gunakan adalah Elastic Load Balancer.</li>
<li>Kemudian, EC2 instance memiliki model harga yang berbeda, di antaranya:</li>
<ol align="justify" type='a'><li> On-Demand adalah yang paling fleksibel dan tidak memiliki kontrak.</li>
<li>Spot Instances memungkinkan Anda untuk menggunakan kapasitas yang tak terpakai dengan tarif diskon.</li>
<li>Reserved Instances dapat memberikan diskon ketika Anda berkomitmen pada tingkat penggunaan tertentu.</li>
<li>Savings Plans juga akan memberikan Anda diskon saat berkomitmen pada tingkat penggunaan tertentu dan dapat diterapkan untuk EC2 instance, AWS Lambda dan AWS Fargate.</li></ol>
<li>Lalu, kita juga telah membahas layanan perpesanan. Ada dua layanan yang kita pelajari:</li>
<ol align="justify" type='a'><li>Amazon Simple Queue Service (Amazon SQS)<br>
SQS memungkinkan Anda untuk melakukan decouple system components (memisahkan komponen sistem). Pesan tetap berada dalam antrean sampai diproses atau dihapus.
<li>Amazon Simple Notification Service (Amazon SNS)<br>
SNS digunakan untuk mengirim pesan seperti email, pesan teks, push notification, atau bahkan permintaan HTTP. Setelah di-publish (diterbitkan), pesan akan terkirim ke semua subscribers (pelanggan).</li></ol>
<li>Berikutnya, kita telah mengetahui bahwa AWS memiliki jenis layanan komputasi di luar server virtual seperti EC2. Ada layanan container (kontainer) seperti Amazon Elastic Container Service (Amazon ECS) dan Amazon Elastic Kubernetes Service (Amazon EKS).
Keduanya merupakan layanan container orchestration (orkestrasi kontainer). Anda dapat menggunakan layanan tersebut dengan EC2 instance.</li>
<li>Namun jika tidak ingin repot-repot mengelolanya, Anda bisa menggunakan AWS Fargate. Layanan ini memungkinkan Anda untuk menjalankan container di atas platform serverless compute (komputasi tanpa server).
Terakhir, ada AWS Lambda. Layanan ini memungkinkan Anda untuk mengunggah kode dan mengonfigurasinya untuk berjalan berdasarkan triggers (pemicu). Anda akan dikenakan biaya hanya pada saat kode berjalan. Tak perlu container atau mesin virtual. Hanya kode dan konfigurasi.</li></ol>

<p align="justify"><b>Pengenalan ke Infrastruktur Global dan Keandalan</b></br>
Selamat datang! Untuk memulai modul ini, mari kita sedikit berbincang tentang high availability (ketersediaan tinggi). Ceritanya begini. Katakanlah pelanggan Anda ingin menikmati secangkir latte hangat di kedai kopi kita. Namun sayangnya, hari ini tak berjalan seperti biasa. Ada parade perayaan keberhasilan migrasi cloud yang menghalangi jalan menuju ke sana dan akan berbaris tepat di depan kedai kopi tersebut.</br></br>
Sebenarnya ini bagus karena siapa yang tak suka melihat balon dan bermandi hujan permen? Akan tetapi, hal ini juga dapat berdampak buruk terhadap bisnis kita karena saat parade berlangsung, pelanggan yang tadinya ingin datang ke kedai kopi akan dialihkan jalannya sehingga tidak bisa mampir. Akibatnya, pelanggan akan kecewa dan penjualan pun menurun.</br></br>
Untungnya, kita telah berpikir jauh ke depan untuk menyiasati gangguan semacam ini. Tahukah Anda? Sebenarnya kedai kopi kita tidak hanya berada di satu tempat saja loh, melainkan terdapat juga di beberapa lokasi lain di seluruh kota.</br></br>
Dengan demikian, Anda tak perlu khawatir lagi jika ada parade di sejumlah ruas jalan. Bahkan tak hanya untuk parade, halangan lain seperti banjir, bencana, atau apa pun yang bisa mencegah pelanggan ke kedai kopi, telah kita atasi.</br></br>
Sekarang kedai kopi kita dapat selalu tersedia bagi pelanggan. Mereka tetap bisa mendapatkan secangkir latte dengan mengunjungi kedai kopi kita lainnya yang berada tidak terlalu jauh. Semuanya akan baik-baik saja, bukan? Kita tetap bisa menjalankan bisnis dan pelanggan tetap bisa mendapatkan kopi.</br></br>
Nah, AWS pun telah melakukan hal yang serupa dengan itu, yaitu dengan menyiapkan infrastruktur global AWS.</br></br>
Tahukah Anda hikmah cerita di atas? Janganlah kita menempatkan semua sumber daya hanya di satu data center saja. Karena jika terjadi hal yang tidak diinginkan pada data center tersebut--seperti pemadaman listrik atau bencana alam--semua aplikasi akan down (mati) sekaligus. Bahkan, memiliki dua data center pun tetap tidak cukup baik loh.</br></br>
Solusinya adalah Anda membutuhkan high availability (ketersediaan tinggi) dan fault tolerance (toleransi terhadap kesalahan). High availability adalah kemampuan untuk memastikan bahwa sistem selalu bekerja dan dapat diakses dengan waktu henti yang minimal tanpa memerlukan intervensi manusia. Sedangkan fault tolerance berarti sistem masih mampu beroperasi meskipun beberapa komponen mengalami kegagalan.</br></br>
Faktanya, AWS beroperasi di lokasi yang berbeda-beda di seluruh dunia yang disebut Region. Tapi sabar ya. Kita baru akan membicarakan hal ini secara mendalam di modul mendatang. Jadi, mari kita lanjutkan!</br></br>
Infrastruktur Global AWS</br></br>
Untuk memahami infrastruktur global AWS, yuk kita mulai dengan menguraikan kebutuhan dasar untuk memulai bisnis di masa sekarang ini. Apa saja? Tentu kita membutuhkan:</p>

<ol align="justify" type='a'><li>Aplikasi yang harus berjalan.</li>
<li>Konten yang perlu disimpan.</li>
<li>Data yang perlu dianalisis.</li></ol>

<p align="justify">Intinya, kita memiliki sesuatu yang harus berjalan dan beroperasi di suatu tempat. Sebelum adanya teknologi Cloud, perusahaan harus menjalankan aplikasi mereka di on-premise karena mereka tak punya pilihan lain. Namun setelah AWS hadir, mereka dapat menjalankannya di data center lain tanpa harus memilikinya. </br></br>
Tetapi pembahasan kita di modul ini akan jauh lebih dari itu. Kita harus memahami masalah yang fundamental terkait data center.</br></br>
Kejadian tak terduga seperti terputusnya koneksi ke data center dapat terjadi kapan pun. Ada banyak faktor yang dapat memengaruhi problem seperti ini, salah satunya adalah bencana.</br></br>
Jika Anda menjalankan on-premise, apa yang akan Anda lakukan saat bencana melanda data center tersebut? Mungkin solusinya adalah membangun data center kedua. Tapi ini bukan solusi yang terbaik.</br></br>
Harga gedung atau bangunan untuk membangun data center akan terlalu mahal bahkan bisa jadi menghentikan bisnis Anda. Belum lagi biaya untuk perangkat keras, karyawan, listrik, pemanas dan pendingin, serta keamanan.</br></br>
Oleh sebab itu, sebagian besar perusahaan pada akhirnya hanya menyimpan data cadangan mereka di suatu tempat dan berharap bencana tidak akan pernah datang. Kita semua tahu, harapan bukanlah rencana bisnis yang baik.</br></br>
Tapi, tenang! AWS dapat membantu Anda mengatasi persoalan tersebut. Solusinya adalah dengan membangun data center dalam kelompok besar yang disebut dengan AWS Regions (Wilayah/Region AWS).</p>

<p align="center">
  <img src="https://github.com/yenysyafitry/Cloud-Practitioner-Essentials-Belajar-Dasar-AWS-Cloud/blob/main/202102231425447e744dc8556f8d1f81ce86009a055bcb.jpeg"></p>

### AWS Well-Architected Framework
<p align="justify">AWS Well-Architected Framework dirancang untuk membantu Anda memahami bagaimana cara merancang dan mengoperasikan sistem yang andal, aman, efisien, dan hemat biaya di AWS Cloud. AWS Well-Architected Framework terdiri dari 5 pilar guna memastikan pendekatan yang konsisten untuk meninjau dan merancang arsitektur.</br>
Mari kita uraikan 5 pilar tersebut:</br></br>
1. Operational Excellence (Keunggulan Operasional)</br>
Pilar ini berfokus untuk menjalankan dan memantau sistem guna memberikan nilai bisnis serta terus meningkatkan proses dan prosedur. Pilar Operational Excellence mencakup bagaimana organisasi Anda mendukung tujuan bisnis, kemampuan untuk menjalankan beban kerja secara efektif, mendapatkan wawasan tentang operasi, dan juga terus meningkatkan proses dan prosedur pendukung untuk memberikan nilai bisnis.</br>
Misalnya, melakukan operation as code (operasi sebagai kode), membuat anotasi dokumentasi, mengantisipasi kegagalan, dan sering memperbaiki prosedur operasi.</br></br>
2. Security (Keamanan)</br>
Seperti yang telah kita pelajari sebelumnya, keamanan adalah prioritas nomor 1 di AWS. Pilar ini akan melindungi informasi, sistem, dan aset Anda sekaligus memberikan nilai bisnis melalui risk assessment (penilaian risiko) dan strategi mitigasi.</br>
Saat mempertimbangkan keamanan arsitektur, implementasikan praktik terbaik berikut:</br>
a. Terapkan keamanan di semua lapisan arsitektur Anda.</br>
b. Lakukan automasi terhadap praktik terbaik keamanan.</br>
c. Lindungi data in-transit dan at rest (sudah kita pelajari di Modul Keamanan).</br></br>
3. Reliability (Keandalan)</br>
Pilar ini mencakup kemampuan sistem untuk memastikan beban kerja melakukan fungsi yang diinginkan dengan benar dan konsisten sesuai harapan.</br>
Beberapa contohnya adalah seperti berikut:</br>
1. Pemulihan otomatis dari kegagalan infrastruktur atau layanan.</br>
2. Horizontal scaling--telah dibahas pada Modul Komputasi di Cloud--untuk meningkatkan ketersediaan beban kerja.</br>
3. Pengujian prosedur pemulihan.</br></br>
4. Performance Efficiency (Efisiensi Kinerja)</br>
Pilar ini berfokus pada penggunaan sumber daya IT dan komputasi secara efisien untuk memenuhi kebutuhan.</br>
Misalnya, menggunakan arsitektur serverless (tanpa server), melakukan eksperimen lebih sering, dan merancang sistem agar dapat mendunia dalam hitungan menit.</br></br>
5. Cost Optimization (Pengoptimalan Biaya)</br>
Pilar ini berfokus untuk mengontrol ke mana uang dibelanjakan guna menghindari biaya yang tak perlu.</br>
Misalnya, menerapkan manajemen keuangan cloud, menganalisis pengeluaran, dan menggunakan managed service (layanan terkelola) untuk mengurangi biaya kepemilikan.  </br>
  

<p align="justify"><b>Kategori: Pemantauan dan Analitik</b></p>
1. Perhatikan pernyataan berikut: 
<ol type='1'><li>Memantau penggunaan dan kinerja sumber daya.</li><li>Mendapatkan panduan real time untuk meningkatkan lingkungan AWS.</li><li>Membandingkan infrastruktur Anda dengan praktik terbaik AWS dalam 5 kategori.</li><li>Mengakses metrik dari satu dashboard.</li><li>Mendeteksi secara otomatis aktivitas akun yang mencurigakan.</li></ol>    
Dari pernyataan di atas, tindakan apa yang dapat Anda lakukan saat menggunakan Amazon CloudWatch?
<ol type='A'>
  <li>1 dan 3</li>
  <li>1 dan 4</li>
  <li>2 dan 5</li>
  <li>3 dan 4</li></ol>
<details><summary markdown="span">Answer :</summary> d</details>
2. Perhatikan beberapa kategori berikut:</br>
 <ol type='1'>
  <li>Reliability</li>
  <li>Performance</li>
  <li>Scalability</li>
  <li>Elasticity</li>
  <li>Fault tolerance</li></ol>
Dari uraian di atas, kategori mana saja yang ada di AWS Trusted Advisor dashboard?
<ol type="a" align="justify"><li> 1 dan 2</li>
<li> 2 dan 3</li>
<li> 2 dan 5</li>
<li> 3 dan 5</li></ol>
<details>
<summary markdown="span">Answer :</summary>
c</details>
3. Manakah layanan yang memungkinkan Anda untuk meninjau keamanan dari Amazon S3 bucket dengan memeriksa izin akses yang terbuka?
  <ol type="a" align="justify">
  <li>Amazon CloudWatch</li>
  <li> Amazon GuardDuty</li>
  <li> AWS Trusted Advisor</li>
  <li> AWS CloudTrail</li></ol>
<details>
<summary markdown="span">Answer :</summary>
b</details>

### Kategori: Harga dan Dukungan

Manakah layanan yang memungkinkan Anda untuk menerima peringatan ketika penggunaan layanan melebihi batas yang telah ditentukan?
- [ ] billing dashboard di aws management console
- [x] aws free tier
- [ ] asw cost explorer
- [ ] aws budget


Perusahaan Anda ingin menerima dukungan dari AWS Technical Account Manager (TAM). AWS Support Plans manakah yang harus Anda pilih?
- [ ] developer
- [ ] business
- [ ] basic
- [x] enterprise


Layanan atau sumber daya manakah yang digunakan untuk menemukan perangkat lunak pihak ketiga yang berjalan di AWS?
- [ ] AWS Support
- [x] AWS Marketplace
- [ ] Billing dasboard di AWS
- [ ] AWS Free tier


Tindakan apa yang dapat Anda lakukan dengan consolidated billing?
- [ ] meninjau perkiraan biaya penggunaan AWS anda pada akhir bulan
- [ ] memvisualisasikan dan mengelola pengeluaran anda dari waktu ke waktu<
- [x] menggabungkan penggunaan di seluruh akun untuk menerima volume pricing discount
- [ ] membuat estimasi biaya terhadap kasus penggunaan anda di AWS


<p align="justify"><b> Knowledge Check : Migrasi dan Inovasi</b></p>
1. Berapa kapasitas penyimpanan dari AWS Snowmobile?<ol type="a" align="justify"><li> 40 PB</li><li> 60 PB</li><li> 80 PB</li><li> 100 PB</li></ol>
  <details><summary markdown="span">Answer :</summary> d. 100 PB</details>  
2. Pada AWS Cloud Adoption Framework, perspektif mana yang dapat membantu Anda menyusun pemilihan dan implementasi dari permission?
<ol type="a" align="justify"><li> Operations</li>
<li> Governance</li>
<li> security</li>
<li> business</li></ol>
<details>
<summary markdown="span">Answer :</summary>
d. business</details>  
3. Perhatikan uraian berikut:
<ol type="1" align="justify"><li> Operations</li>
<li>Revisiting</li>
<li>Retaining</li>
<li>Remembering</li>
<li>Redeveloping</li>
<li>Rehosting</li></ol>
Strategi apa saja yang termasuk ke dalam 6 strategi untuk memigrasikan aplikasi?
<ol type="a" align="justify"><li> Operations</li><li> 1 dan 3</li>
<li> 2 dan 4</li>
<li> 2 dan 5</li>
<li> 3 dan 4</li></ol>
<details>
<summary markdown="span">Answer :</summary>
c. 2 dan 5</details> 
4. Manakah pernyataan yang paling tepat untuk menggambarkan Amazon Lex?
<ol type="a" align="justify"><li>layanan yang memungkinkan anda untuk mengidentifikasi aktivitas online yang berpotensi penipuan</li>
<li>layanan yang memungkinkan anda untuk membangun antarmuka percakapan menggunakan suara dan teks</li>
<li>layanan machine learning yang secara otomatis mengekstrak teks dan data dari dokumen yang di pindai</li>
<li>layanan database dokumen yang mendukung beban kerja mongoDB</li></ol>
<details>
<summary markdown="span">Answer :</summary>
b.layanan yang memungkinkan anda untuk membangun antarmuka percakapan menggunakan suara dan teks </br> Amazon Lex : Layanan ini adalah solusi AI siap pakai yang dapat membantu Anda dalam membangun chatbot interaktif.</details> 
5. Perhatikan pernyataan berikut:
<ol type="1" align="justify"><li>Meningkatkan kecepatan dan ketangkasan.</li>
<li>Mendapatkan manfaat dari skala ekonomi yang lebih kecil.</li>
<li>Mengubah pengeluaran variabel menjadi pengeluaran di muka.</li>
<li>Mempertahankan kapasitas infrastruktur.</li>
<li>Menghentikan biaya pengelolaan dan pemeliharaan data center.</li></ol>
Dari pernyataan di atas, mana sajakah yang termasuk ke dalam manfaat komputasi cloud?
<ol type="A" align="justify"> <li> 1 dan 3</li><li> 1 dan 5</li><li> 2 dan 4</li><li> 3 dan 5</li></ol>
  <details><summary markdown="span">Answer :</summary>
B. 1 dan 5</details> 
6. Pada AWS Well-Architected Framework, manakah pilar yang menyertakan kemampuan untuk menjalankan beban kerja secara efektif dan mendapatkan wawasan ke dalam operasinya?
<ol type="a" align="justify"><li>reliability</li>
<li>operational excellence </li>
<li>performance efficiency</li>
<li>cost optimization</li></ol>
 <details><summary markdown="span">Answer :</summary>
b. operational excellence </details>




Kategori: Ujian Akhir

#### Anda ingin Amazon S3 memantau pola akses dari objek Anda. Kelas penyimpanan mana yang harus Anda gunakan?
- [ ] S3 One Zone-IA
- [ ] S3 Glacier
- [x] S3 Intelligent- Tiering
- [ ] S3 Standar-IA


#### Anda menjalankan Amazon EC2 instance dan ingin menyimpan data di dalam suatu tempat penyimpanan. Data Anda bersifat sementara dan tidak akan disimpan dalam jangka panjang. Sumber daya mana yang harus Anda gunakan?
- [ ] Subnet
- [ ] Amazon EBS Bolume
- [x] Instance Store
- [ ] Amazon S3 Bucket


#### Layanan mana yang memungkinkan Anda untuk menggabungkan dan mengelola beberapa akun AWS dari satu lokasi terpusat?
- [ ] AWS Artifact
- [x] AWS Organizations
- [ ] AWS Key Management Service (AWS KMS)
- [ ] AWS Identity and Access Management (IAM)

#### Perhatikan beberapa pernyataan berikut:
Memantau aplikasi Anda dan merespons perubahan performa di seluruh sistem. </br>
Menghubungkan permintaan pengguna ke infrastruktur di AWS dan di luar AWS.</br>
Mengelola DNS records untuk nama domain.</br>
Mengakses laporan keamanan dan compliance AWS serta online agreements tertentu.</br>
Mengotomatiskan penerapan beban kerja ke lingkungan AWS Anda.</br>
Mana saja tindakan yang dapat Anda lakukan di Amazon Route 53?
- [ ] 1 dan 2
- [ ] 2 dan 3
- [ ] 2 dan 4
- [ ] 3 dan 5

#### Layanan mana yang dapat meninjau detail aktivitas pengguna dan panggilan API dalam lingkungan AWS Anda?
- [ ] aws trusted advisor
- [ ] amazon cloudwatch
- [ ] amazon inspector
- [x] aws cloud trail


#### Komponen atau layanan mana yang dapat membuat koneksi terdedikasi antara data center Anda dan virtual private cloud (VPC)?
- [ ] internet gateway
- [ ] amazon cloud front
- [ ] virtual private gateway
- [x] aws direct connect


#### Anda ingin menyimpan data dalam database key-value. Layanan mana yang harus Anda gunakan?
- [ ] amazon RDS
- [x] amazon dynamoDB
- [ ] amazon aurora
- [ ] amazon documentdb


#### Anda ingin mengirim dan menerima pesan antara komponen aplikasi terdistribusi. Layanan mana yang harus Anda gunakan?
- [ ] amazon elasticache
- [ ] amazon sqs
- [ ] aws snowball
- [ ] amazon route 53

#### Layanan apa yang digunakan untuk mentransfer hingga 80 PB data ke AWS?
- [ ] aws snowmobile
- [ ] amazon neptune
- [ ] aws deepracer
- [ ] amazon cloudfront


#### Manakah layanan yang digunakan untuk memvisualisasikan, memahami, serta mengelola biaya dan penggunaan AWS Anda dari waktu ke waktu?
- [ ] aws budgets
- [ ] aws pricing calculator
- [ ] aws free tier
- [x] aws cost explorer


#### Pada AWS Trusted Advisor, kategori manakah yang mencakup pemeriksaan terhadap service limits dan penggunaan instance yang berlebih?
- [ ] performance
- [ ] security
- [ ] cost optimization
- [ ] fault tolerance


#### Opsi komputasi mana yang dapat mengurangi biaya jika Anda berkomitmen pada jumlah penggunaan komputasi yang konsisten untuk jangka waktu 1 atau 3 tahun?
- [ ] spot instances
- [ ] savings plans
- [ ] reserved instances
- [ ] dedicated hosts


#### Pernyataan mana yang paling tepat untuk menggambarkan Amazon GuardDuty?
- [ ] layanan yang menyediakan intelligent smart detection untuk infastruktur dan sumber daya aws
- [ ] layanan yang membantu melindungi aplikasi anda dari serangan distributed denial of service(DDoS)
- [ ] layanan yang bisa memeriksa kerentanan keamanan dan penyimpanan aplikasi dari praktik terbaik keamanan
- [ ] layanan yang dapat memantau permintaan jaringan masuk ke aplikasi web anda


#### Perhatikan uraian berikut:
Enterprise </br>
Developer </br>
Business </br>
Basic </br>
AWS Free Tier </br>
AWS Support Plans mana yang menyertakan akses ke semua pemeriksaan AWS Trusted Advisor?
- [ ] 1dan 3
- [ ] 2 dan 3
- [ ] 2 dan 5
- [ ] 4 dan 5
Jawaban antara A dan B, kunci benar no 3 Business


#### Pernyataan mana yang paling tepat menggambarkan Availability Zone?
- [x] lokasi geografis terpisah dengan beberapa lokasi yang terisolasi satu sama lain
- [ ] lokasi yang digunakan amazon cloudfront untuk menyimpan salinan konten kedalam cache agar pengiriman lebih cepat kepada pengguna di seluruh dunia
- [ ] bagian dari insfrastuktur global aws yang terisolasi sepenuhnya
- [ ] server tempat amazon cloudfront mendapatkan file anda


#### Layanan mana yang memungkinkan anda membuat alur kerja untuk peninjauan manusia terhadap prediksi machine learning
- [ ] amazon augmentanted al
- [ ] amazon lex
- [ ] amazon textract
- [ ] amazon aurora

#### layanan apa yang digunakan untuk menjalankan containerized application di AWS ?
- [ ] amazon redshift
- [ ] amazon aurora
- [ ] amazon EKS
- [ ] amazon sagemaker

#### Strategi migrasi manakah yang melibatkan perubahan tentang bagaimana cara aplikasi 
- [ ] refactoring
- [ ] rehosting
- [x] replatforming
- [ ] repurchasing
 
#### Manakah dari layanan berikut yang dapat membuat estimasi biaya untuk
- [x] aws pricing calculator
- [ ] aws cost explorer
- [ ] aws cost and usage report
- [ ] aws budgets
 
#### anda ingin menyimpan data dalam volume yang di attach ke amazon ec2 instance layanan
- [ ] aws lambda
- [ ] amazon elasticache
- [ ] amazon s3
- [x] amazon ebs

 
#### pada aws cloud adaption framework, perspektif manakah yang berfokus terhadap pemulihan beban kerja IT untuk memenuhi kebutuhan business stakeholder anda ?
- [ ] operations
- [ ] governance
- [ ] business
- [ ] people
 
 
 #### pernyataan mana yang paling tepat untuk menggambarkan elastic load balacing ?
- [ ] layanan yang dapat memantau aplikasi anda dan secara otomatis menambah atau mengurangi kapasitas dari resoutce group sebagai respon terhdap permintaan
- [ ] layanan yang memungkinkan anda untuk menyiapkan, mengelola, dan melakukan memory atau cache yang terdistribusi di cloud
- [ ] layanan yang mendistribusikan lalu lintas masuk ke beberapa target seperti amazon ec2 instance
- [ ] layanan yang menyediakan data untuk memantau aplikasi, mengoptimalkan penggunaan sumber daya, dan merespon perubahan perfoma di seluruh sistem
 
 
 #### layanan apa yang digunakan untuk mengotomasikan tindakan pada layanan dan aplikasi aws melalui skrip?
- [ ] amazon refshift
- [ ] aws command line interface
- [ ] aws snowball
- [ ] amazon qldb
 
 
 #### pernyataan mana yang paling tepat untuk menggambarkan aws marketplace
- [ ] katalog digital yang mencangkup ribuan perangkat lunak dari berbagai vendor
- [ ] layanan online yang memeriksa lingkungan aws anda dan memberikan panduan secara real time sesuai dengan praktik terbaik aws
- [ ] sumber daya yang dapat menjawab pertanyaan tentang praktik terbaik dan membantu memecahkan masalah
- [ ] sumber daya yang memberikan panduan, tinjauan arsitektur, dan komunikasi berkelanjutan terhadap lingkungan aws anda
 
Strategi migrasi manakah yang melibatkan perubahan tentang bagaimana cara aplikasi dirancang dan dikembangkan menggunakan fitur cloud-native?
- [ ] replatforming
- [ ] repurchasing
- [x] rehosting

Komponen virtual private cloud (VPC) mana yang mengontrol lalu lintas masuk dan keluar untuk Amazon EC2 instance


Pada AWS Cloud Adoption Framework, perspektif manakah yang berfokus terhadap pemulihan beban kerja IT untuk memenuhi kebutuhan business stakeholder Anda



Layanan apa yang digunakan untuk mengotomatiskan tindakan pada layanan dan aplikasi AWS melalui skrip?


 
##### Komponen atau layanan mana yang dapat membuat koneksi terdedikasi antara data center anda dan virtual private cloud (VPC)?
- [ ] amazon coudfront</li>
- [ ] internet gateway</li>
- [x] aws direct connect</li>
- [ ] virtual private gateway

##### Layanan mana yang digunakan untuk melakukan deploy dan scaling aplikasi dengan cepat di AWS ?
- [ ] AWS Snowball
- [ ] Amazon CloudFront
- [ ] AWS Outposts
- [ ] AWS Elastic Beanstalk

##### Layanan apa yang digunakan untuk menjalankan contrainerized application di AWS
- [ ] Amazon Aurora
- [ ] Amazon EKS
- [ ] Amazon SageMaker
- [ ] Amazon Redshift

##### Anda ingin menyimpan data dalam volume yang di attach ke amazon EC2 Instance. layanan mana yang harus anda gunakan ?
- [ ] AWS Lambda
- [ ] Amazon S3
- [ ] Amazon ElastiCache
- [ ] Amazon EBS

##### Pada AWS Trusted Advisor kategori manakah yang mencangkup pemeriksaan terhadap service limits dan penggunaan instance yang berlebihan
- [ ] performance
- [ ] security
- [ ] cost optimization
- [ ] fault tolerance

##### Pernyataan mana yang benar terkait AWS Lambda
- [ ] sebelum menggunakan AWS Lambda anda harus membayar di muka untuk perkiraan waktu komputasi
- [ ] anda hanya membayar untuk waktu komputasi saat kode berjalan
- [ ] untuk menggunakan AWS Lambda anda harus mengonfigurasi server terlebih dahulu
- [ ] langkah pertama dalam menggunakan AWS Lambda adalah menyediakan server




